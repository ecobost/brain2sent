# Written by: Erick Cobos T
# Date: 03-Aug-2016
"""
This is NOT a script.

It is a log of the different things I needed to test before training the big 
models. It is not polished as I was just collecting the different results and
checking what could work. This wouldn't work as is because I have renamed some
data files and deleted some others that I end up not using.


SUMMARY:
I tested some things for preprocessing data. I decided:
+ To average the image feature vectors over an entire second rather than just
	subsample them every 15 frames.
+ To use the image feature vectors as outputted by the network rather than
	accesing them before the ReLU (so they could have negative values).
+ To test with a smoothed version of the BOLD activations. Smoothed with a 
	gaussian filter (std = 1.5secs). I would also train with the normal BOLD.


I decided to go for the following models*:

1 Fit an l1-regularized regression (Lasso) on all input features (no voxel 
	selection). The regularization parameter (called alpha in scikit-learn) is
	selected via 5-fold cross-validation in a range from high to low sparsity 
	(100 alphas given by scikit-learn)
2 Fit an l2-regularized regression (Ridge) on all input features (no voxel
	selection). The regularization parameter (called alpha in scikit-learn) is
	selected via 5-fold cross-validation in the range {10^x | x in [3.5, 3.6,
	3.7, 3.8 ..., 5.2, 5.3, 5.4, 5.5]}
3 Select best features using an F test (f_regression) and fit a ridge regression.
	Number of features k in range {5, 10, 25, 50, 75, 100, 250, 500, 750,
	1000, 2500, 5000}. Regularization parameter in range {10^x | x in [2.5, 2.6,
	2.7, ..., 4.8, 4.9, 5]}
4 Use ROIs as feature selection. Fit a separate ridge regression for each ROI 
	and retain the one that gave the best CV. Regularization parameter in range
	10^x | x in [2.5, 2.6, 2.7, ..., 4.8, 4.9, 5]}.
5 Use the trained lasso model as feature selection. Select all features that 
	have a coefficient different than zero in the lasso model and fit a ridge
	regression. Regularization parameter cross-validated in range {10^x | x in 
	[1, 1.1, 1.2, 1.3, ..., 3.7, 3.8, 3.9, 4]}.
6 Use the trained ridge model as feature selection. Choose the k features with 
	highest absolute value and refit a ridge regression model. k and 
	regularization parameter cross-validated as in 3.
7 Fit a neural network with a single hidden layer with 400 units, output is the 
	768-d vector representing the image vectors. Trained with SGD+NAG, learning 
	rate is divided by 5 if the training loss has not decreased in two epochs, 
	training stops when learning rate is too small. Regularization parameter 
	(called alpha by scikit-learn) is searched using 5-fold cv in range {10^x | 
	x in {1.5, 1.55, 1.6, ..., 2.4, 2.45, 2.5}}

* All models (except for the neural network) are fitted for each of the 768 
output units to predict.

Other things that could be tried:
+ Feature selection with ExtraTrees.
+ Other regression models: random Forest/ExtraTrees, SVR, Nearest Neighbor
+ Dimensionality reduction: PCA

See train_models.py for the scikit-learn code defining and training each model.
"""
import numpy as np
import h5py
# Read input
Xs_file = h5py.File('train_bold.h5', 'r')
Xs = np.array(Xs_file['responses'])
Xs_file.close()

# Read regression targets
y_file = h5py.File('train_1sec_feats.h5', 'r')
y = np.array(y_file['feats'])
y_file.close()
 
# Delay it 5 secs and drop first and last 10 samples
delay = 5
Xs = Xs[10 + delay: -10 + delay, :]
y = y[10:-10, :]

# Get last 10% as test set. I se feature 3 for tests. Hopefully, is a good proxy.
X_train = Xs[:-718, :]; y_train = y[:-718, 3]; X_test = Xs[-718:,:]; y_test = y[-718:, 3]
# Baseline mse (predicting y_train.mean()) = 0.025472971





###############################################################################
# Testing selectK best
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn import linear_model

num_features = [1, 3, 10, 31, 100, 316, 1000, 3160]
ridge_alphas = [10, 31.6, 100, 316, 1000, 3160, 10000, 31600, 100000]
for k in num_features:
	print(k, 'feature(s)'); selector = SelectKBest(f_regression, k=k).fit(X_train, y_train); X_new = selector.transform(X_train); X_test_new = selector.transform(X_test); model = linear_model.RidgeCV(alphas=ridge_alphas, cv=5).fit(X_new, y_train); y_pred = model.predict(X_test_new); mse = ((y_test - y_pred)**2).mean(); print('Ridge: alpha =', model.alpha_, 'mse =', mse); model = linear_model.LassoCV(cv=5, n_jobs=-1, selection='random', random_state=123, eps = 0.008).fit(X_new, y_train); print('Min', model.alphas_.min(), 'Max', model.alphas_.max()); sparsity = (model.coef_ != 0).sum(); y_pred = model.predict(X_test_new); mse = ((y_test - y_pred)**2).mean(); print('Lasso: alpha=', model.alpha_, 'sparsity =', sparsity , 'mse =', mse)

# Results for selectKBest
1 feature(s)
Ridge: alpha = 316 mse = 0.0193451730488
Lasso: alpha= 0.000199906355795 sparsity = 1 mse = 0.0193563506232
3 feature(s)
Ridge: alpha = 316 mse = 0.0191307509213
Lasso: alpha= 0.000135325402801 sparsity = 3 mse = 0.0191628579329
10 feature(s)
Ridge: alpha = 1000 mse = 0.0186510786721
Lasso: alpha= 0.000613744360206 sparsity = 9 mse = 0.018682844637
31 feature(s)
Ridge: alpha = 1000 mse = 0.018971001032
Lasso: alpha= 0.000710444639961 sparsity = 23 mse = 0.0190695104827
100 feature(s)
Ridge: alpha = 3160 mse = 0.018676169905
Lasso: alpha= 0.00147653545676 sparsity = 50 mse = 0.0187523667855
316 feature(s)
Ridge: alpha = 3160 mse = 0.0188596154879
Lasso: alpha= 0.00155033227947 sparsity = 134 mse = 0.0188013253002
1000 feature(s)
Ridge: alpha = 10000 mse = 0.0187657339141
Lasso: alpha= 0.00188429296401 sparsity = 288 mse = 0.0193014498216
3160 feature(s)
Ridge: alpha = 10000 mse = 0.0187265410358
Lasso: alpha= 0.00179459939597 sparsity = 739 mse = 0.0191146389525
All features (no feature selection)
Ridge: alpha = 31600 mse = 0.0182215347193
Lasso: alpha= 0.00347872947997 sparsity = 343 mse = 0.0185642872093

# Ridge is always better (and the regularization term could be better selected via cv)

# For f_regression maybe select anything with p < 0.01 (instead of going for different number of features) or add this to the option of number of features. something like [1, 2, 3, 5, 10 , 25, 70, 500, 1000, (selector.pvalues_ < 0.01).sum(), (selector.pvalues_ < 0.001).sum()] Make sure these are not zero, otherwise the whole thing will crash.

# Test using the LOOCV rather than 5 cv for ridge
for k in num_features:
	print(k, 'feature(s)'); selector = SelectKBest(f_regression, k=k).fit(X_train, y_train); X_new = selector.transform(X_train); X_test_new = selector.transform(X_test); model = linear_model.RidgeCV(alphas=ridge_alphas).fit(X_new, y_train); y_pred = model.predict(X_test_new); mse = ((y_test - y_pred)**2).mean(); print('Ridge: alpha =', model.alpha_, 'mse =', mse);

1 feature(s)
Ridge: alpha = 100.0 mse = 0.0193551832689
3 feature(s)
Ridge: alpha = 100.0 mse = 0.0191561625298
10 feature(s)
Ridge: alpha = 316.0 mse = 0.0186798388242
31 feature(s)
Ridge: alpha = 316.0 mse = 0.0190873807304
100 feature(s)
Ridge: alpha = 1000.0 mse = 0.018848967138
316 feature(s)
Ridge: alpha = 3160.0 mse = 0.018859615626
1000 feature(s)
Ridge: alpha = 3160.0 mse = 0.019277270148
3160 feature(s)
Ridge: alpha = 10000.0 mse = 0.0187265390582
All feats
Ridge: alpha = 31600.0 mse = 0.0182215347193
# Selects smaller alphas and results are slightly worse when it does so. It is faster, though (not quite 5x).

# Test another y_i
y5_train = y[:-718, 5]
y5_test = y[-718:, 5]

for k in num_features:
	print(k, 'feature(s)'); selector = SelectKBest(f_regression, k=k).fit(X_train, y5_train); X_new = selector.transform(X_train); X_test_new = selector.transform(X_test); model = linear_model.RidgeCV(alphas=ridge_alphas, cv=5).fit(X_new, y5_train); y5_pred = model.predict(X_test_new); mse = ((y5_test - y5_pred)**2).mean(); print('Ridge: alpha =', model.alpha_, 'mse =', mse); model = linear_model.LassoCV(cv=5, n_jobs=-1, selection='random', random_state=123, eps = 0.008).fit(X_new, y5_train); print('Min', model.alphas_.min(), 'Max', model.alphas_.max()); sparsity = (model.coef_ != 0).sum(); y5_pred = model.predict(X_test_new); mse = ((y5_test - y5_pred)**2).mean(); print('Lasso: alpha=', model.alpha_, 'sparsity =', sparsity , 'mse =', mse)
	
1 feature(s)
Ridge: alpha = 31.6 mse = 0.0313072994508
Lasso: alpha= 0.000385105024423 sparsity = 1 mse = 0.0313062022563
3 feature(s)
Ridge: alpha = 316 mse = 0.031644974755
Lasso: alpha= 0.000385105024423 sparsity = 3 mse = 0.031638848892
10 feature(s)
Ridge: alpha = 3160 mse = 0.0318372528349
Lasso: alpha= 0.00130347262705 sparsity = 9 mse = 0.031823262039
31 feature(s)
Ridge: alpha = 3160 mse = 0.0313485807876
Lasso: alpha= 0.00245727484769 sparsity = 16 mse = 0.031313630266
100 feature(s)
Ridge: alpha = 3160 mse = 0.0308838979964
Lasso: alpha= 0.00234030697011 sparsity = 40 mse = 0.0309568527152
316 feature(s)
Ridge: alpha = 3160 mse = 0.0301621903717
Lasso: alpha= 0.00222890683941 sparsity = 105 mse = 0.0305949741133
1000 feature(s)
Ridge: alpha = 10000 mse = 0.0287189387462
Lasso: alpha= 0.00270904084922 sparsity = 242 mse = 0.0292954022182
3160 feature(s)
Ridge: alpha = 10000 mse = 0.0278673440986
Lasso: alpha= 0.00298660214166 sparsity = 519 mse = 0.0295853446381
# This goes from 31.6 to 10000 alpha. Also, best was in 3160


# And another just to be sure y_i
y5_train = y[:-718, 100]
y5_test = y[-718:, 100]

1 feature(s)
Ridge: alpha = 316 mse = 0.0430027341081
Lasso: alpha= 0.000305072878063 sparsity = 1 mse = 0.0429948025532
3 feature(s)
Ridge: alpha = 316 mse = 0.0432209442601
Lasso: alpha= 0.000206517246254 sparsity = 3 mse = 0.0432272192428
10 feature(s)
Ridge: alpha = 3160 mse = 0.0430950707528
Lasso: alpha= 0.00131774347944 sparsity = 10 mse = 0.0431234001582
31 feature(s)
Ridge: alpha = 3160 mse = 0.0426921968199
Lasso: alpha= 0.00287557979514 sparsity = 18 mse = 0.0427062736123
100 feature(s)
Ridge: alpha = 3160 mse = 0.0411894804371
Lasso: alpha= 0.00194660641236 sparsity = 58 mse = 0.0410441381884
316 feature(s)
Ridge: alpha = 3160 mse = 0.0403293577006
Lasso: alpha= 0.00248417791101 sparsity = 154 mse = 0.040071063323
1000 feature(s)
Ridge: alpha = 10000 mse = 0.0400486951881
Lasso: alpha= 0.00260833641735 sparsity = 348 mse = 0.0408686093885
3160 feature(s)
Ridge: alpha = 10000 mse = 0.0400413138872
Lasso: alpha= 0.00317020423562 sparsity = 642 mse = 0.0400374050188
# Yeah I will need something bigger than 10000 because some are gonna need that
# and maybe something slightly smaller than 100.

del y5, y5_train y5_test, y5_pred 





###############################################################################
# Testing with normal features (not averaged over 1sec)

# Read regression targets
y2_file = h5py.File('train_feats.h5', 'r')
y2 = np.array(y2_file['feats'])
y2_file.close()

y2 = y2[10:-10, :]
y2_train = y2[:-718, 3]
y2_test = y2[-718:, 3]

# How different they are?
Subsampled (y2_train, y2_train.std())
mean = 0.1431753, std = 0.152648
1sec (y_train)
mean = 0.14328392, std = 0.13918754
# Same mean but slightly less variance. Makes sense
corr = 0.85578866 # So not exactly equal
(y_train == 0).sum() = 918
(y2_train == 0).sum() = 1968
# Quite more zeros in the subsampled version (again, as expected)

# In plotting they look pretty similar except that the 1sec version is less exagerated (peaks are not as high), it has less zero, because in the 15 frames it was averaged at least one probably had other different than zero. Otherwise, kind of the same, I like the 1sec version better, it is probably truer to reality.

# Are results much different?
num_features = [1, 3, 10, 31, 100, 316, 1000, 3160]
ridge_alphas = [10, 31.6, 100, 316, 1000, 3160, 10000, 31600, 100000]
for k in num_features:
	print(k, 'feature(s)'); selector = SelectKBest(f_regression, k=k).fit(X_train, y2_train); X_new = selector.transform(X_train); X_test_new = selector.transform(X_test); model = linear_model.RidgeCV(alphas=ridge_alphas, cv=5).fit(X_new, y2_train); y2_pred = model.predict(X_test_new); mse = ((y2_test - y2_pred)**2).mean(); print('Ridge: alpha =', model.alpha_, 'mse =', mse); model = linear_model.LassoCV(cv=5, n_jobs=-1, selection='random', random_state=123, eps = 0.008).fit(X_new, y2_train); print('Min', model.alphas_.min(), 'Max', model.alphas_.max()); sparsity = (model.coef_ != 0).sum(); y2_pred = model.predict(X_test_new); mse = ((y2_test - y2_pred)**2).mean(); print('Lasso: alpha=', model.alpha_, 'sparsity =', sparsity , 'mse =', mse)

1 feature(s)
Ridge: alpha = 100 mse = 0.0252800283064
Lasso: alpha= 0.00012447515569 sparsity = 1 mse = 0.0252803612046
3 feature(s)
Ridge: alpha = 316 mse = 0.0252221846815
Lasso: alpha= 0.000130696388614 sparsity = 3 mse = 0.0252448330584
10 feature(s)
Ridge: alpha = 1000 mse = 0.0251653823199
Lasso: alpha= 0.000363967563206 sparsity = 10 mse = 0.025274593093
31 feature(s)
Ridge: alpha = 1000 mse = 0.0250013556365
Lasso: alpha= 0.000686142784955 sparsity = 28 mse = 0.0250986211279
100 feature(s)
Ridge: alpha = 3160 mse = 0.0245972044289
Lasso: alpha= 0.0013581484116 sparsity = 57 mse = 0.0248419695539
316 feature(s)
Ridge: alpha = 3160 mse = 0.0245867338374
Lasso: alpha= 0.00181983781603 sparsity = 132 mse = 0.0246929585683
1000 feature(s)
Ridge: alpha = 10000 mse = 0.0243015366922
Lasso: alpha= 0.00200629367415 sparsity = 304 mse = 0.0248499015724
3160 feature(s)
Ridge: alpha = 10000 mse = 0.0243754628386
Lasso: alpha= 0.00200629367415 sparsity = 734 mse = 0.0251553122045
# This seems wrong, if they are so similar why would the fit be so bad.
# Plus y_pred and y2_pred are quite similar (mean diff is 0.0012) so it is pretty much learning the same.
# There is nothing wrong. It is learning around the same it is just that the subsampled version is quite noisy so the y_test will expect noisy answers, for instance the subsampled version has peaks or valleys (that last a single second) where the averaged has not meaning that just in that second there was something totallly different going on (somethiong like dog in second 0-3, no dog in second 4, dog in second 4-7) but as the video is continuos this doesn't quite add up, maybe it just happen that that frame had something different and the subsampled version catched that. Yep, averag over 1 sec is quite better (takes alittle noise 0out of the already quite noisy data.

del y2, y2_train y2_test, y2_pred 






###############################################################################
# Testing with features recorded before the RELU in the convnet. This will have both positive and negative values (not only positive) as the normal ones.


# Read regression targets
y3_file = h5py.File('train_feats_wo_relu.h5', 'r') # No relu/averaged over 1 sec
y3 = np.array(y3_file['feats'])
y3_file.close()

y3 = y3[10:-10, :]
y3_train = y3[:-718, 3]
y3_test = y3[-718:, 3] # y_test is equal to this but with all negatives send to zero.

num_features = [1, 3, 10, 31, 100, 316, 1000, 3160]
ridge_alphas = [10, 31.6, 100, 316, 1000, 3160, 10000, 31600, 100000]
for k in num_features:
	print(k, 'feature(s)'); selector = SelectKBest(f_regression, k=k).fit(X_train, y3_train); X_new = selector.transform(X_train); X_test_new = selector.transform(X_test);
	model = linear_model.RidgeCV(alphas=ridge_alphas, cv=5).fit(X_new, y3_train); y3_pred = model.predict(X_test_new); mse = ((y3_test - y3_pred)**2).mean(); y3_pred[y3_pred < 0] = 0; mse2 = ((y_test - y3_pred)**2).mean(); print('Ridge: alpha =', model.alpha_, 'mse =', mse, 'mse2 =', mse2);
	model = linear_model.LassoCV(cv=5, n_jobs=-1, selection='random', random_state=123, eps = 0.008).fit(X_new, y3_train); print('Min', model.alphas_.min(), 'Max', model.alphas_.max()); sparsity = (model.coef_ != 0).sum(); y3_pred = model.predict(X_test_new); mse = ((y3_test - y3_pred)**2).mean(); y3_pred[y3_pred < 0] = 0; mse2 = ((y_test - y3_pred)**2).mean(); print('Lasso: alpha=', model.alpha_, 'sparsity =', sparsity , 'mse =', mse, 'mse2 =', mse2)

1 feature(s)
Ridge: alpha = 316 mse = 0.0349971975841 mse2 = 0.0221583522705
Lasso: alpha= 0.000220577585725 sparsity = 1 mse = 0.0350238681169 mse2 = 0.0221953100882
3 feature(s)
Ridge: alpha = 1000 mse = 0.0346210062056 mse2 = 0.022058214069
Lasso: alpha= 0.000436610431905 sparsity = 3 mse = 0.0346588781308 mse2 = 0.0221336333489
10 feature(s)
Ridge: alpha = 316 mse = 0.0340131825871 mse2 = 0.022098772828
Lasso: alpha= 0.000396033833475 sparsity = 9 mse = 0.0340428127682 mse2 = 0.0221314536461
31 feature(s)
Ridge: alpha = 1000 mse = 0.0336698749675 mse2 = 0.0218266031307
Lasso: alpha= 0.00218305215952 sparsity = 15 mse = 0.033885423004 mse2 = 0.0219153649749
100 feature(s)
Ridge: alpha = 3160 mse = 0.0333453833768 mse2 = 0.0219829000697
Lasso: alpha= 0.00292515960725 sparsity = 31 mse = 0.0334655016971 mse2 = 0.0221098961792
316 feature(s)
Ridge: alpha = 3160 mse = 0.032752771119 mse2 = 0.0222750168244
Lasso: alpha= 0.00322486386656 sparsity = 94 mse = 0.0324801270661 mse2 = 0.0218454085681
1000 feature(s)
Ridge: alpha = 10000 mse = 0.0319847950218 mse2 = 0.0218010486521
Lasso: alpha= 0.00240672201634 sparsity = 294 mse = 0.0319544909149 mse2 = 0.0220760970334
3160 feature(s)
Ridge: alpha = 10000 mse = 0.0320022033308 mse2 = 0.0219051928925
Lasso: alpha= 0.00252700929906 sparsity = 725 mse = 0.0322022164097 mse2 = 0.0223584844
# So it is worse, why?. I thought having the negative values will encourage it 
# to learn more. Maybe now it is trying to fit the negative parts, too and then 
# when that goes to zero, it loses all that work.
# I still kind of thing that if I had more data it would probably be better to
# use this features.

# I also tested correlation with y_test (k=100)
0.20099122 for y_pred (computed with y_train)
0.17280401 for y3_pred (computed with y3_train and sett everything negative to zero)
0.20258783 for y_pred after setting the lowest 100 to zero (simulating the same level of sparsity as y_train)
0.17232713 for y3_pred after setting the lowest 100 to zero.

# Yep, it's worse. Stick with ReLUed ones

del y3, y3_train y3_test, y3_pred 





###############################################################################
# Testing setting a number of outputs to zero trying to simulate the sparsity 
# of the desired output (using as proxy the sparsity of y_train). Or changing the
# spread so it has the same standard deviation as the expected output (again using
# as proxy the y_train)

k=100
print(k, 'feature(s)')
selector = SelectKBest(f_regression, k=k).fit(X_train, y_train)
X_new = selector.transform(X_train)
X_test_new = selector.transform(X_test)
model = linear_model.RidgeCV(alphas=ridge_alphas, cv=5).fit(X_new, y_train)
y_pred = model.predict(X_test_new)
y_p = y_pred.copy()
# y_train has 0.142 percent of values equal to zero. That is equal to 102 in y_test
# (y_pred < 0.0991).sum() = 102, so
y_p[y_pred < 0.0991] = 0

# Corr for y_pred is 0.20099122 (mse 0.01867)
# corr for y_p is 0.19958189  (mse 0.02002)
# however if i set 101 (instead of 102) elemtns to zero (y_pred < 0.1), corr is 0.20258783, so it can be improved if the number is right.

# What about also improving the spread?
# All predictions have small std (spread), so if i increase the spread by subtracting the y_train.mean() multiplying it by some number and adding the y_train.mean() again (so that all values below the y_mean go lower and all above go higher), I'll probably get better results

# Or better use the predictions on the train set as a proxy of the difference between the std of the true y_pred (y_train)
y_train_pred = model.predict(X_new)
y_p = y_pred.copy()
expected_mean = y_train_pred.mean()
expected_std = y_train_pred.std()
desired_mean = y_train.mean() 
desired_std = y_train.std()
# the expected mean (0.143283) and desired mean(0.143283) are quite similar, i.e., 
# the model learns the mean of the outputs (usually in the bias/intercept term).
# the expected std (0.04207434) and desired_std (0.139187) though are different
# showing that the model is conservative and predicts things closer to the mean.

# Normalize
y_p = (y_p - expected_mean)/expected_std
# Give new spread
y_p = (y_p * desired_std) + desired_mean

# Plots look fine, it does now have kind of the same spread as the y_test
np.corrcoef(y_p, y_test) = 0.2009912
# Correlation didn't change as all we did was scale it (makes sense). Any linear
# transformation will still produce the same correlation. Mse however, should
# improve as now the features are closer in the 718-d space
((y_pred - y_test)**2).mean() = 0.018676169904963687
((y_p - y_test)**2).mean() = 0.028894233007613852 
# Nop :) I guess it is because the predictions are not as good

# But now, it predict negative numbers which I can set to zero as
y_p [y_p < 0] = 0
np.corrcoef(y_p, y_test) = 0.21247009 # goes up :)
((y_p - y_test)**2).mean() = 0.025909022 # goes down

# And if I try to induce the same sparsity as I did before
y_p[y_pred < 0.0991] = 0
np.corrcoef(y_p, y_test) = 0.21247009
((y_p - y_test)**2).mean() = 0.025909022 
# In fact, nothing changes here because setting to zero above already set the 
# lowest 104 to zero. I like that.

# So I can slightly improve correlation but mse goes down quite a bit (considering 0.0254 is thye baseline).
# Maybe that will change resulkts????

# Plus as the output of this is to be taken by the RNN maybe it is better to 
# have it go in the same spread because that is teh scale the RNN is expecting.

# Anyway, this is post-processing so it is probably better to present results 
# both wo and with this postprocessing. And choose then.

# It is quite important that I don't use any statistic extracted from the test set,
# not from test set features or test_set real labels or test_set predicted labels,
# everything could be done even if i had a single test set point. All is extracted
# from the training set.

# Plotting this against y_test looks quite better than plotting y_pred, that single
# 0.01 change in correlation is quite visible.





###############################################################################
# Testing smoothing the BOLD ativations temporally.
from scipy import ndimage
k=100
for std in [1, 2, 3, 5, 8, 10, 20]:
	print('Smoothed. std=', std); X_smooth = ndimage.gaussian_filter1d(X_train, std, 0); X_smooth = (X_smooth - X_smooth.mean(axis=0))/X_smooth.std(axis=0); X_test_smooth = ndimage.gaussian_filter1d(X_test, std, 0); X_test_smooth = (X_test_smooth - X_smooth.mean(axis=0))/X_smooth.std(axis=0)

	selector = SelectKBest(f_regression, k=k).fit(X_smooth, y_train); X_new = selector.transform(X_smooth); X_test_new = selector.transform(X_test_smooth);

	model = linear_model.RidgeCV(alphas=ridge_alphas, cv=5).fit(X_new, y_train); y_pred = model.predict(X_test_new); mse = ((y_test - y_pred)**2).mean(); print('Ridge: alpha =', model.alpha_, 'mse =', mse)

	model = linear_model.LassoCV(cv=5, n_jobs=-1, selection='random', random_state=123, eps = 0.008).fit(X_new, y_train); print('Max', model.alphas_.max(), 'Min', model.alphas_.min()); sparsity = (model.coef_ != 0).sum(); y_pred = model.predict(X_test_new); mse = ((y_test - y_pred)**2).mean(); print('Lasso: alpha=', model.alpha_, 'sparsity =', sparsity , 'mse =', mse)

# Tested by selecting the best 100 features with f_regression (separate for each model)
Normal 
Ridge: alpha = 3160 mse = 0.018676169905
Lasso: alpha= 0.00147653545676 sparsity = 50 mse = 0.0187523667855
Smoothed. std= 1
Ridge: alpha = 3160 mse = 0.0183967540448
Lasso: alpha= 0.00144694883455 sparsity = 64 mse = 0.0183892257329
Smoothed. std= 2
Ridge: alpha = 3160 mse = 0.0186137775244
Lasso: alpha= 0.00167033041265 sparsity = 59 mse = 0.0186122930673
Smoothed. std= 3
Ridge: alpha = 3160 mse = 0.0186012957738
Lasso: alpha= 0.00250148000215 sparsity = 53 mse = 0.0184625232682
Smoothed. std= 5
Ridge: alpha = 3160 mse = 0.0184542335409
Lasso: alpha= 0.00232399977777 sparsity = 48 mse = 0.0184104627988
Smoothed. std= 8
Ridge: alpha = 3160 mse = 0.0186771524289
Lasso: alpha= 0.00211054250093 sparsity = 54 mse = 0.0186959443378
Smoothed. std= 10
Ridge: alpha = 3160 mse = 0.0188072426215
Lasso: alpha= 0.00218829393143 sparsity = 51 mse = 0.0188154946324
Smoothed. std= 20
Ridge: alpha = 10000 mse = 0.0191955361617
Lasso: alpha= 0.00325127354768 sparsity = 32 mse = 0.0192277241503
# Consistently better. May be because it is bringing knowledge from previous/future
# timesteps instead of using a single delay (so it kind of assumes a gaussian hrf).
# An odd thing is that lasso in this case is consistently better than Ridge.
# Also it is good for std=1, bad for std=2,3, relatively good againg for std=5 and quite bad agin for std=8 and up

# Imma try it with 300 features but for another y_i (to select a std)
y4_train = y[:-718, 5]
y4_test = y[-718:, 5]
k=300

for std in [1, 2, 3, 5, 8, 10, 20]:
	print('Smoothed. std=', std); X_smooth = ndimage.gaussian_filter1d(X_train, std, 0); X_smooth = (X_smooth - X_smooth.mean(axis=0))/X_smooth.std(axis=0); X_test_smooth = ndimage.gaussian_filter1d(X_test, std, 0); X_test_smooth = (X_test_smooth - X_smooth.mean(axis=0))/X_smooth.std(axis=0)

	selector = SelectKBest(f_regression, k=k).fit(X_smooth, y4_train); X_new = selector.transform(X_smooth); X_test_new = selector.transform(X_test_smooth);

	model = linear_model.RidgeCV(alphas=ridge_alphas, cv=5).fit(X_new, y4_train); y4_pred = model.predict(X_test_new); mse = ((y4_test - y4_pred)**2).mean(); print('Ridge: alpha =', model.alpha_, 'mse =', mse)

	model = linear_model.LassoCV(cv=5, n_jobs=-1, selection='random', random_state=123, eps = 0.008).fit(X_new, y4_train); print('Max', model.alphas_.max(), 'Min', model.alphas_.min()); sparsity = (model.coef_ != 0).sum(); y4_pred = model.predict(X_test_new); mse = ((y4_test - y4_pred)**2).mean(); print('Lasso: alpha=', model.alpha_, 'sparsity =', sparsity , 'mse =', mse)

Normal
Ridge: alpha = 3160 mse = 0.0301175581331
Lasso: alpha= 0.00212280942724 sparsity = 102 mse = 0.0303893116312
Smoothed. std= 1
Ridge: alpha = 3160 mse = 0.0295984696287
Lasso: alpha= 0.00396326162263 sparsity = 59 mse = 0.030286748991
Smoothed. std= 2
Ridge: alpha = 3160 mse = 0.0292038162638
Lasso: alpha= 0.0038658493776 sparsity = 61 mse = 0.0296605678201
Smoothed. std= 3
Ridge: alpha = 3160 mse = 0.029276691546
Lasso: alpha= 0.00405214938716 sparsity = 63 mse = 0.0294840829659
Smoothed. std= 5
Ridge: alpha = 3160 mse = 0.0302324850159
Lasso: alpha= 0.00352369211508 sparsity = 63 mse = 0.0303588724737
Smoothed. std= 8
Ridge: alpha = 10000 mse = 0.0321759556154
Lasso: alpha= 0.00734807520086 sparsity = 27 mse = 0.032503593896
Smoothed. std= 10
Ridge: alpha = 3160 mse = 0.0324502876996
Lasso: alpha= 0.00679160293294 sparsity = 32 mse = 0.0330574465054
Smoothed. std= 20
Ridge: alpha = 10000 mse = 0.0332863839995 
Lasso: alpha= 0.00683864138666 sparsity = 39 mse = 0.0334058385649 # didn't converge
# Lasso is worse now. Results are consistently better again and plateau at std=2 (kinda makes sense). std=1 is not as good as in the other examples


# Let's test it with yet another one
y4_train = y[:-718, 100]
y4_test = y[-718:, 100]
k=300

Normal
Ridge: alpha = 3160 mse = 0.0405022062561
Lasso: alpha= 0.00248417791101 sparsity = 147 mse = 0.0401582021196
Smoothed. std= 1
Ridge: alpha = 10000 mse = 0.0400178433661
Lasso: alpha= 0.00437446573606 sparsity = 102 mse = 0.0400674398656
Smoothed. std= 2
Ridge: alpha = 10000 mse = 0.0401437964831
Lasso: alpha= 0.00474687630362 sparsity = 91 mse = 0.0400570101381
Smoothed. std= 3
Ridge: alpha = 10000 mse = 0.0405363662789
Lasso: alpha= 0.00515060647608 sparsity = 88 mse = 0.0406556341862
Smoothed. std= 5
Ridge: alpha = 10000 mse = 0.0413890243855
Lasso: alpha= 0.00539554344253 sparsity = 75 mse = 0.0413921618115
Smoothed. std= 8
Ridge: alpha = 31600 mse = 0.042618120245
Lasso: alpha= 0.00546075903161 sparsity = 69 mse = 0.042278015445
Smoothed. std= 10
Ridge: alpha = 31600 mse = 0.0429490661876
Lasso: alpha= 0.00531723367775 sparsity = 66 mse = 0.0427328297172
Smoothed. std= 20
Ridge: alpha = 31600 mse = 0.0437572606873
Lasso: alpha= 0.00724604415293 sparsity = 41 mse = 0.0438210841314 # didn't converge
# std=1 is better than others std (2 is still acceptable).

# Not sure whether 1 or 2 is a better std. I'll test another one.
y4_train = y[:-718, 300]
y4_test = y[-718:, 300]
k=300

Normal
Ridge: alpha = 3160 mse = 0.0183645834642
Lasso: alpha= 0.0017072460303 sparsity = 112 mse = 0.0184297697829
Smoothed. std= 1
Ridge: alpha = 3160 mse = 0.0181444501117
Lasso: alpha= 0.00235231066948 sparsity = 92 mse = 0.0179438976407
Smoothed. std= 2
Ridge: alpha = 3160 mse = 0.0180515494809
Lasso: alpha= 0.00244942214296 sparsity = 85 mse = 0.0178005409809
Smoothed. std= 3
Ridge: alpha = 3160 mse = 0.0180642031221
Lasso: alpha= 0.0027684640458 sparsity = 75 mse = 0.0179841793608
Smoothed. std= 5
Ridge: alpha = 10000 mse = 0.0183017200076
Lasso: alpha= 0.00344006552382 sparsity = 59 mse = 0.018045466841
Smoothed. std= 8
Ridge: alpha = 10000 mse = 0.0182646761465
Max 0.0148579645425 Min 0.00011886371634
Lasso: alpha= 0.00312011227795 sparsity = 51 mse = 0.0181561594239
Smoothed. std= 10
Ridge: alpha = 10000 mse = 0.0184655579629
Lasso: alpha= 0.00351045191188 sparsity = 44 mse = 0.0184454376779 #didn't converge
Smoothed. std= 20
Ridge: alpha = 10000 mse = 0.0186560970461
Lasso: alpha= 0.00277989524867 sparsity = 46 mse = 0.0187501623562 #didn't converge
# std = 2 is better again. Results are better overall. Maybe stick with 1.5


# Test the smoothed(std=1.5) with diff features in the y_train
num_features = [1, 3, 10, 31, 100, 316, 1000, 3160]
std=1.5
X_smooth = ndimage.gaussian_filter1d(X_train, std, 0); X_smooth = (X_smooth - X_smooth.mean(axis=0))/X_smooth.std(axis=0); X_test_smooth = ndimage.gaussian_filter1d(X_test, std, 0); X_test_smooth = (X_test_smooth - X_smooth.mean(axis=0))/X_smooth.std(axis=0)
for k in num_features:
	print(k, 'feature(s)'); selector = SelectKBest(f_regression, k=k).fit(X_smooth, y_train); X_new = selector.transform(X_smooth); X_test_new = selector.transform(X_test_smooth);
	model = linear_model.RidgeCV(alphas=ridge_alphas, cv=5).fit(X_new, y_train); y_pred = model.predict(X_test_new); mse = ((y_test - y_pred)**2).mean(); print('Ridge: alpha =', model.alpha_, 'mse =', mse); 
	model = linear_model.LassoCV(cv=5, n_jobs=-1, selection='random', random_state=123, eps = 0.008).fit(X_new, y_train); print('Min', model.alphas_.min(), 'Max', model.alphas_.max()); sparsity = (model.coef_ != 0).sum(); y_pred = model.predict(X_test_new); mse = ((y_test - y_pred)**2).mean(); print('Lasso: alpha=', model.alpha_, 'sparsity =', sparsity , 'mse =', mse)


1 feature(s)
Ridge: alpha = 316 mse = 0.0191694913008
Min 0.000168149298776 Max 0.021018662347
Lasso: alpha= 0.000301901986874 sparsity = 1 mse = 0.019170954979
3 feature(s)
Ridge: alpha = 1000 mse = 0.0190520887221
Min 0.000168149298776 Max 0.021018662347
Lasso: alpha= 0.000800726415105 sparsity = 3 mse = 0.0190523746713
10 feature(s)
Ridge: alpha = 1000 mse = 0.0190371239615
Lasso: alpha= 0.00112655012529 sparsity = 10 mse = 0.019068242443
31 feature(s)
Ridge: alpha = 1000 mse = 0.0184393879801
Lasso: alpha= 0.00102185365287 sparsity = 25 mse = 0.0184857604736
100 feature(s)
Ridge: alpha = 3160 mse = 0.0185386284349
Lasso: alpha= 0.0013692229097 sparsity = 61 mse = 0.0186458330232
316 feature(s)
Ridge: alpha = 3160 mse = 0.0187167519323
Lasso: alpha= 0.00222988902136 sparsity = 103 mse = 0.0185475658638
1000 feature(s)
Ridge: alpha = 10000 mse = 0.0181268651463
Lasso: alpha= 0.00245835766144 sparsity = 192 mse = 0.0184483895772
3160 feature(s)
Ridge: alpha = 10000 mse = 0.0176693582849
Lasso: alpha= 0.00245835766144 sparsity = 365 mse = 0.0184727807949
# That was unexpectedly good. Plus, there is a gradiet of being better for more
# features (and alpha gets high, too but still not the highest)
# Also, Lasso takes a lot of time and is quite worse.

# Also tested it for 5000 features as above (Ridge: alpha = 10000 mse = 0.0176105107288) and for std=5 (3160 feature(s): Ridge: alpha = 31600 mse = 0.018474939248). 5000 is slightly better.


# Conclusion: Do run experiments with the smoothed version (std=1.5) and non-smoothed. And also do run for 5000 features and only ridge.

del y4, y4_train y4_test, y4_pred 





###############################################################################
# Timing how much it would take ridge and lasso on all features for feature y_3
import time

model = linear_model.RidgeCV(alphas=ridge_alphas, cv=5);
t1 = time.time()
model.fit(X_train, y_train)
t_ridge_cv = time.time() - t1
print(t_ridge_cv)
y_pred = model.predict(X_test)
mse = ((y_test - y_pred)**2).mean()
print('Ridge: alpha =', model.alpha_, 'mse =', mse)
# t = 133.06 (2.21 min)
# Ridge: alpha = 31600 mse = 0.0182215347193
# Nice, doesn't take much and produces good results witouth much hassle.
# there was an alpah=10000 so it didn't even use the highest alpha.
# Without OpenBlas, this takes over 3 hours.


model = linear_model.LassoCV(cv=5, n_jobs=-1, selection='random', random_state=123, eps = 0.01)
t1 = time.time()
model.fit(X_train, y_train)
t_lasso_cv = time.time() - t1
print(t_lasso_cv)
print('Max', model.alphas_.max(), 'Min', model.alphas_.min())
sparsity = (model.coef_ != 0).sum()
y_pred = model.predict(X_test)
mse = ((y_test - y_pred)**2).mean()
print('Lasso: alpha=', model.alpha_, 'sparsity =', sparsity , 'mse =', mse)
# t = 1189.38 (19.82 min)
# Lasso: alpha= 0.00347872947997 sparsity = 343 mse = 0.0185642872093
# would take 10 days and results aren't as good. I was expecting this to be better





###############################################################################
# Test the ROI version thing
# Read ROI assignments
roi_file = h5py.File('roi_info.h5', 'r')
roi = np.array(roi_file['rois'])
roi_file.close()

# Get masks
masks = {}
masks['v1'] = (roi == 19) | (roi == 20)
masks['v2'] = (roi == 21) | (roi == 22)
masks['v3'] = (roi == 27) | (roi == 28)
masks['v3a'] = (roi == 23) | (roi == 24)
masks['v3b'] = (roi == 25) | (roi == 26)
masks['v4'] = (roi == 29) | (roi == 30)
masks['lo'] = (roi == 17) | (roi == 18)
masks['mt'] = (roi == 5) | (roi == 6) | (roi == 7) | (roi == 8) #v5
masks['ip'] = (roi == 3) | (roi == 4)
masks['vo'] = (roi == 15) | (roi == 16)
masks['OBJ'] = (roi == 9) | (roi == 10) #?
masks['rsc'] = (roi == 13)
masks['sts'] = (roi == 14)
for ROI_name, mask in masks.items():
	print(ROI_name,':', mask.sum(), 'features'); X_new = X_train[:, mask]; X_test_new = X_test[:, mask]; model = linear_model.RidgeCV(alphas=ridge_alphas, cv=5).fit(X_new, y_train); y_pred = model.predict(X_test_new); mse = ((y_test - y_pred)**2).mean(); print('Ridge: alpha =', model.alpha_, 'mse =', mse); model = linear_model.LassoCV(cv=5, n_jobs=-1, selection='random', random_state=123, eps = 0.01).fit(X_new, y_train); print('Max', model.alphas_.max(), 'Min', model.alphas_.min()); sparsity = (model.coef_ != 0).sum(); y_pred = model.predict(X_test_new); mse = ((y_test - y_pred)**2).mean(); print('Lasso: alpha=', model.alpha_, 'sparsity =', sparsity , 'mse =', mse)
	
ip : 2251 features
Ridge: alpha = 10000 mse = 0.0187121158387
Lasso: alpha= 0.00293632192558 sparsity = 231 mse = 0.0188190286733
v3a : 252 features
Ridge: alpha = 10000 mse = 0.0187463976904
Lasso: alpha= 0.00254477658378 sparsity = 64 mse = 0.0187399163802
v1 : 994 features
Ridge: alpha = 31600 mse = 0.0192935254364
Lasso: alpha= 0.00359299573451 sparsity = 74 mse = 0.0192534876104
OBJ : 163 features
Ridge: alpha = 10000 mse = 0.0190032666555
Lasso: alpha= 0.00258242770317 sparsity = 53 mse = 0.018953917105
vo : 410 features
Ridge: alpha = 10000 mse = 0.0187250231285
Lasso: alpha= 0.00268487966143 sparsity = 97 mse = 0.0188348540851
lo : 722 features
Ridge: alpha = 10000 mse = 0.0188253936249
Lasso: alpha= 0.00200021331775 sparsity = 210 mse = 0.0191386408637
mt : 466 features
Ridge: alpha = 10000 mse = 0.0187577759497
Lasso: alpha= 0.00294958332898 sparsity = 86 mse = 0.018910062142
sts : 45 features
Ridge: alpha = 100000 mse = 0.0193121068679
Lasso: alpha= 0.00636122329665 sparsity = 0 mse = 0.0193221658188
v2 : 1477 features
Ridge: alpha = 31600 mse = 0.019470167435
Lasso: alpha= 0.00411921457495 sparsity = 63 mse = 0.019210554996
v4 : 734 features
Ridge: alpha = 10000 mse = 0.0186581361689
Lasso: alpha= 0.00224547202347 sparsity = 160 mse = 0.0187459548216
v3b : 256 features
Ridge: alpha = 3160 mse = 0.0185048601184
Lasso: alpha= 0.00258662048078 sparsity = 87 mse = 0.0187338340224
rsc : 71 features
Ridge: alpha = 3160 mse = 0.0191780867289
Lasso: alpha= 0.00125019054522 sparsity = 44 mse = 0.0192245958442
v3 : 1141 features
Ridge: alpha = 31600 mse = 0.0193227580453
Lasso: alpha= 0.00359351300226 sparsity = 87 mse = 0.0193904209834
# kind of average results (0.185-0.187) in a lot of ROIs. Smaller alpha is 3160
# (10**3.5) and bigger alpha was 31600 (10**4.5), so maybe try it only with 
# bigger alphas. 10**(3-5)


# Try it with another y_i
y6_train = y[:-718, 5]
y6_test = y[-718:, 5]

for ROI_name, mask in masks.items():
	print(ROI_name,':', mask.sum(), 'features'); X_new = X_train[:, mask]; X_test_new = X_test[:, mask]; model = linear_model.RidgeCV(alphas=ridge_alphas, cv=5).fit(X_new, y6_train); y6_pred = model.predict(X_test_new); mse = ((y6_test - y6_pred)**2).mean(); print('Ridge: alpha =', model.alpha_, 'mse =', mse); model = linear_model.LassoCV(cv=5, n_jobs=-1, selection='random', random_state=123, eps = 0.01).fit(X_new, y6_train); print('Max', model.alphas_.max(), 'Min', model.alphas_.min()); sparsity = (model.coef_ != 0).sum(); y6_pred = model.predict(X_test_new); mse = ((y6_test - y6_pred)**2).mean(); print('Lasso: alpha=', model.alpha_, 'sparsity =', sparsity , 'mse =', mse)
	
ip : 2251 features
Ridge: alpha = 10000 mse = 0.0308855504854
Lasso: alpha= 0.00400181996869 sparsity = 256 mse = 0.0309644845896
v3a : 252 features
Ridge: alpha = 10000 mse = 0.0321421488408
Lasso: alpha= 0.00366210439647 sparsity = 66 mse = 0.0322195520732
v1 : 994 features
Ridge: alpha = 10000 mse = 0.0316913662661
Lasso: alpha= 0.00390463198001 sparsity = 148 mse = 0.0312489480532
OBJ : 163 features
Ridge: alpha = 3160 mse = 0.0319064740871
Lasso: alpha= 0.00405153865901 sparsity = 44 mse = 0.0317213987357
vo : 410 features
Ridge: alpha = 3160 mse = 0.0304249441308
Lasso: alpha= 0.00221788037459 sparsity = 189 mse = 0.0301266462979
lo : 722 features
Ridge: alpha = 10000 mse = 0.032910244523
Lasso: alpha= 0.00459410872374 sparsity = 98 mse = 0.0329809555544
mt : 466 features
Ridge: alpha = 10000 mse = 0.0319795473444
Lasso: alpha= 0.00304405231226 sparsity = 161 mse = 0.0321604842432
sts : 45 features
Ridge: alpha = 31600 mse = 0.0332738978859
Lasso: alpha= 0.0107699556137 sparsity = 0 mse = 0.0333765696274
v2 : 1477 features
Ridge: alpha = 10000 mse = 0.0307579439957
Lasso: alpha= 0.00363398663213 sparsity = 236 mse = 0.0310465460723
v4 : 734 features
Ridge: alpha = 10000 mse = 0.0333350014734
Lasso: alpha= 0.00282842295764 sparsity = 203 mse = 0.0323518178529
v3b : 256 features
Ridge: alpha = 3160 mse = 0.0326728720724
Lasso: alpha= 0.0034641184187 sparsity = 68 mse = 0.0324062824028
rsc : 71 features
Ridge: alpha = 3160 mse = 0.0329103098971
Lasso: alpha= 0.00265715193829 sparsity = 33 mse = 0.0324777428148
v3 : 1141 features
Ridge: alpha = 10000 mse = 0.0315121304323
Lasso: alpha= 0.00373590665814 sparsity = 212 mse = 0.0313712096561
# 0.030 in vo, ip (still worse than f_regression). High alphas, too.

del y6, y6_train y6_test, y6_pred 






###############################################################################
# Fit an ordinary linear model to see whether it overfits. Yep, it does.
model = linear_model.LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test_new)
mse = ((y_test - y_pred)**2).mean()
print('Linear Regression: mse =', mse)

Linear Regression: mse = 1.52775774527
# Wildly overfits. Takes a long time, too.

# Use the weights as feature selection
sorted_indices = abs(model.coef_).argsort()

for k in num_features:
	print(k, 'feature(s)'); selected_features = sorted_indices[-k:]; X_new = X_train[:, selected_features]; X_test_new = X_test[:, selected_features];
	model = linear_model.RidgeCV(alphas=ridge_alphas, cv=5).fit(X_new, y_train); y_pred = model.predict(X_test_new); mse = ((y_test - y_pred)**2).mean(); print('Ridge: alpha =', model.alpha_, 'mse =', mse); model = linear_model.LassoCV(cv=5, n_jobs=-1, selection='random', random_state=123, eps = 0.008).fit(X_new, y_train); print('Min', model.alphas_.min(), 'Max', model.alphas_.max()); sparsity = (model.coef_ != 0).sum(); y_pred = model.predict(X_test_new); mse = ((y_test - y_pred)**2).mean(); print('Lasso: alpha=', model.alpha_, 'sparsity =', sparsity , 'mse =', mse)
	
1 feature(s)
Ridge: alpha = 3160 mse = 0.0193359925193
Lasso: alpha= 2.422115595e-05 sparsity = 1 mse = 0.0193451448598
3 feature(s)
Ridge: alpha = 1000 mse = 0.0193654270057
Lasso: alpha= 4.52400746928e-05 sparsity = 3 mse = 0.0193803659414
10 feature(s)
Ridge: alpha = 10000 mse = 0.019359608142
Lasso: alpha= 0.0056550093366 sparsity = 1 mse = 0.0193221658192
31 feature(s)
Ridge: alpha = 3160 mse = 0.0189222740885
Lasso: alpha= 0.00216765666897 sparsity = 15 mse = 0.0188953893778
100 feature(s)
Ridge: alpha = 10000 mse = 0.0191179935357
Lasso: alpha= 0.00210924042808 sparsity = 47 mse = 0.0190391119692
316 feature(s)
Ridge: alpha = 10000 mse = 0.0194310242953
Lasso: alpha= 0.00355612917641 sparsity = 51 mse = 0.0191132484336
1000 feature(s)
Ridge: alpha = 10000 mse = 0.0189461914724
Lasso: alpha= 0.00262245457614 sparsity = 187 mse = 0.0193127331903
3160 feature(s)
Ridge: alpha = 10000 mse = 0.0187013939087
Lasso: alpha= 0.00289114446382 sparsity = 339 mse = 0.019056575336
# Results are somehow good because the Ridge, Lasso can still learn something 
# even if feats are somehow random. Still, f_regression is better.






###############################################################################
# Test a neural network and see what kind of regularization should it use
# Baseline correlation: 0.526314
from sklearn.neural_network import MLPRegressor

hidden_layer_size = [50, 100, 300, 600, 1000, 1500, 2000]
regularization_params = [10, 21.5, 46.3, 100, 215, 463, 1000, 2150, 4630, 10000, 21500]
y_train = y[:-718]; y_test =y[-718:]

for layer_size in hidden_layer_size:
	print('Layer size:', layer_size)
	for alpha in regularization_params:
		print('alpha = ', alpha); model = MLPRegressor(hidden_layer_sizes = (layer_size,), alpha=alpha, max_iter=1000, random_state=123, early_stopping=True, tol = 1e-8); model.fit(X_train, y_train); y_pred = model.predict(X_test); mse = ((y_pred-y_test)**2).mean(); mse3 = ((y_pred[:,3] - y_test[:,3])**2).mean(); corr = 0; corrf = 0;
		for i in range(718):
			corr +=  np.corrcoef(y_pred[i,:], y_test[i,:])[0,1]
		for i in range(768):
			corrf +=  np.corrcoef(y_pred[:,i], y_test[:,i])[0,1]
		corr =	corr/718; corrf =	corrf/768; print('mse =', mse, 'mse3 =',mse3, 'corr =', corr, 'corr/f =', corrf)
		
# Results. Slightly worse than fitting a ridge per feature but easier/faster
Layer size: 50
alpha =  10
mse = 0.0257794951244 mse3 = 0.0223201188953 corr = 0.475850131809 corr/f = 0.0529520142246
alpha =  21.5
mse = 0.0242249855181 mse3 = 0.0208086534726 corr = 0.506984272708 corr/f = 0.0600512462354
alpha =  46.3
mse = 0.0230861075072 mse3 = 0.0196558398647 corr = 0.533839972878 corr/f = 0.0667489643735
alpha =  100
mse = 0.0218639488688 mse3 = 0.0193035890575 corr = 0.564555705951 corr/f = 0.0682887109243
alpha =  215
mse = 0.0212770194296 mse3 = 0.0192422686163 corr = 0.572942119843 corr/f = 0.07834037493
alpha =  463
mse = 0.0214436296667 mse3 = 0.0193405502465 corr = 0.565277988664 corr/f = 0.00347691794447
alpha =  1000
mse = 0.0213355846686 mse3 = 0.0193231800619 corr = 0.567563383215 corr/f = 0.00613067976954
alpha =  2150
mse = 0.0213397212161 mse3 = 0.0193270911939 corr = 0.567462174522 corr/f = 0.0017997517905
alpha =  4630
mse = 0.0213398353438 mse3 = 0.0193273113344 corr = 0.567459801195 corr/f = 0.00464508241859
alpha =  10000
mse = 0.021339818236 mse3 = 0.0193273888153 corr = 0.56746023488 corr/f = 0.00612134107906
alpha =  21500
mse = 0.0213398201414 mse3 = 0.0193274589446 corr = 0.56746004767 corr/f = -0.00156667390074
Layer size: 100
alpha =  10
mse = 0.0258631621736 mse3 = 0.0227344928271 corr = 0.471930747042 corr/f = 0.0480801354604
alpha =  21.5
mse = 0.0252741449719 mse3 = 0.021152285919 corr = 0.489634513372 corr/f = 0.043305588632 # Not sure what happen here, if this point looks odd then recompute.
alpha =  46.3
mse = 0.0231419263243 mse3 = 0.0193468815388 corr = 0.533864854189 corr/f = 0.0608995757062
alpha =  100
mse = 0.0216490637053 mse3 = 0.018890554959 corr = 0.567559948874 corr/f = 0.0765636772797
alpha =  215
mse = 0.0211889650818 mse3 = 0.0193733712221 corr = 0.571786788095 corr/f = 0.0660530958462
alpha =  463
mse = 0.0214296611932 mse3 = 0.019352664085 corr = 0.565534615723 corr/f = 0.00491760980511
alpha =  1000
mse = 0.0213456723867 mse3 = 0.0193258733664 corr = 0.567357518334 corr/f = 0.013733524184
alpha =  2150
mse = 0.0213394322316 mse3 = 0.019328770254 corr = 0.567475894533 corr/f = -0.0040017622255
alpha =  4630
mse = 0.0213394858494 mse3 = 0.0193280082184 corr = 0.567476886 corr/f = 0.00287664537525
alpha =  10000
mse = 0.0213394667719 mse3 = 0.019327350433 corr = 0.567477735846 corr/f = 0.00175524885843
alpha =  21500
mse = 0.0213394448105 mse3 = 0.0193272032291 corr = 0.56747841095 corr/f = 0.00166323039771
Layer size: 300
alpha =  10
mse = 0.0260725378251 mse3 = 0.0228571570571 corr = 0.470441155721 corr/f = 0.0384161393257
alpha =  21.5
mse = 0.0251110313619 mse3 = 0.0211006520892 corr = 0.496196150552 corr/f = 0.0400270241815
alpha =  46.3
mse = 0.0232015322766 mse3 = 0.0194845099388 corr = 0.533432614286 corr/f = 0.0616957571677
alpha =  100
mse = 0.0219354229974 mse3 = 0.0192759896709 corr = 0.564954651682 corr/f = 0.0683304329853
alpha =  215
mse = 0.0212039626318 mse3 = 0.019342100062 corr = 0.57310391036 corr/f = 0.0802871382986
alpha =  463
mse = 0.0213705932058 mse3 = 0.0193239345303 corr = 0.566903191901 corr/f = 0.0104376740773
alpha =  1000
mse = 0.0213424901302 mse3 = 0.0193266136762 corr = 0.567386906087 corr/f = 0.0127275071293
alpha =  2150
mse = 0.0213328988273 mse3 = 0.0193034814474 corr = 0.567652606723 corr/f = 0.0072176873177
alpha =  4630
mse = 0.0213361177634 mse3 = 0.0193061046394 corr = 0.567572092199 corr/f = 0.000697572759059
alpha =  10000
mse = 0.0213370602796 mse3 = 0.019307164774 corr = 0.567549561938 corr/f = -0.00282093413539
alpha =  21500
mse = 0.0213374263114 mse3 = 0.0193076680987 corr = 0.56754092582 corr/f = -0.000853125875355
Layer size: 600
alpha =  10
mse = 0.0260887206105 mse3 = 0.0215400722144 corr = 0.471187788438 corr/f = 0.0399059834396
alpha =  21.5
mse = 0.0247148040095 mse3 = 0.0221236013114 corr = 0.498721047373 corr/f = 0.0495444465389
alpha =  46.3
mse = 0.0232557987956 mse3 = 0.0201565579994 corr = 0.534112591889 corr/f = 0.06215584304
alpha =  100
mse = 0.0219352254296 mse3 = 0.0199665756205 corr = 0.569983391721 corr/f = 0.0779436978553
alpha =  215
mse = 0.0212320864021 mse3 = 0.0194206775555 corr = 0.572862293871 corr/f = 0.0784011805555
alpha =  463
mse = 0.0213820923424 mse3 = 0.0193250634939 corr = 0.566509428758 corr/f = 0.0124097807367
alpha =  1000
mse = 0.0213415308323 mse3 = 0.0193262015748 corr = 0.567403155821 corr/f = 0.0171636298828
alpha =  2150
mse = 0.0213455453224 mse3 = 0.0193216153386 corr = 0.567329610688 corr/f = 0.00215253033149
alpha =  4630
mse = 0.0213370161142 mse3 = 0.0193090150245 corr = 0.567548647894 corr/f = -0.00175419291273
alpha =  10000
mse = 0.0213395374043 mse3 = 0.0193276619304 corr = 0.567465458904 corr/f = 0.00421691427993
alpha =  21500
mse = 0.0213395223843 mse3 = 0.0193268807089 corr = 0.567466448453 corr/f = 0.000253731896486
Layer size: 1000
alpha =  10
mse = 0.0265585833527 mse3 = 0.0230378402865 corr = 0.471990661908 corr/f = 0.0310937981763
alpha =  21.5
mse = 0.0249892793224 mse3 = 0.0225323133461 corr = 0.49236495663 corr/f = 0.0497230041675
alpha =  46.3
mse = 0.0235179005409 mse3 = 0.0205721973155 corr = 0.53182893376 corr/f = 0.0582233499612
alpha =  100
mse = 0.0220826922109 mse3 = 0.0204719708317 corr = 0.568199958608 corr/f = 0.0746761624304
alpha =  215
mse = 0.0211937234369 mse3 = 0.0194136479731 corr = 0.572410708259 corr/f = 0.0674437600081
alpha =  463
mse = 0.021377704465 mse3 = 0.0193348774486 corr = 0.566795891669 corr/f = 0.0110049776324
alpha =  1000
mse = 0.0213364260758 mse3 = 0.0193348376804 corr = 0.567564849236 corr/f = -0.00341983140096
alpha =  2150
mse = 0.0213401648489 mse3 = 0.0193204923822 corr = 0.567466095663 corr/f = -0.00427633714749
alpha =  4630
mse = 0.021331757624 mse3 = 0.019318327796 corr = 0.56768415739 corr/f = 0.00573835307107
alpha =  10000
mse = 0.0213346897015 mse3 = 0.0193142161331 corr = 0.567613266848 corr/f = -0.000437152774056
alpha =  21500
mse = 0.0213356661625 mse3 = 0.019310546446 corr = 0.567589071613 corr/f = -0.000470723273639
Layer size: 1500
alpha =  10
mse = 0.0261710037941 mse3 = 0.0221435929699 corr = 0.478628008497 corr/f = 0.0374274742501
alpha =  21.5
mse = 0.025362436466 mse3 = 0.0213998734551 corr = 0.498368365331 corr/f = 0.0406728035666
alpha =  46.3
mse = 0.0237691069191 mse3 = 0.0209187486333 corr = 0.528700049579 corr/f = 0.0562011832864
alpha =  100
mse = 0.021777175282 mse3 = 0.0197335973784 corr = 0.571901742482 corr/f = 0.0830747514617
alpha =  215
mse = 0.0212040915712 mse3 = 0.0195057068127 corr = 0.573143506854 corr/f = 0.0688530993488
alpha =  463
mse = 0.021337164306 mse3 = 0.0193401682495 corr = 0.567488772056 corr/f = 0.0195911854038
alpha =  1000
mse = 0.0213822068461 mse3 = 0.0193231488836 corr = 0.566837653255 corr/f = 0.00885475609409
alpha =  2150
mse = 0.0213406152518 mse3 = 0.0193184726228 corr = 0.567455827405 corr/f = -0.00690930570814
alpha =  4630
mse = 0.0213331387496 mse3 = 0.0193257845825 corr = 0.567640122872 corr/f = 0.00771921659787
alpha =  10000
mse = 0.0213346096265 mse3 = 0.0193151925181 corr = 0.567629360016 corr/f = -0.00107231469099
alpha =  21500
mse = 0.0213359216314 mse3 = 0.0193123518948 corr = 0.567599934545 corr/f = 0.00288799178625
Layer size: 2000
alpha =  10
mse = 0.026432061277 mse3 = 0.0220081146551 corr = 0.475715025432 corr/f = 0.0327682490817
alpha =  21.5
mse = 0.0252208670348 mse3 = 0.0241684256146 corr = 0.492265311105 corr/f = 0.0532512693596
alpha =  46.3
mse = 0.0239662303282 mse3 = 0.020253853335 corr = 0.527043110978 corr/f = 0.0531655050424
alpha =  100
mse = 0.0219310590395 mse3 = 0.0196766822472 corr = 0.570598865182 corr/f = 0.0753504516038
alpha =  215
mse = 0.0212345891837 mse3 = 0.0194837699112 corr = 0.573167131208 corr/f = 0.0677792074444
alpha =  463
mse = 0.021336924672 mse3 = 0.0193509673273 corr = 0.567507466933 corr/f = 0.0213079405048
alpha =  1000
mse = 0.0213276449261 mse3 = 0.0193436306615 corr = 0.567813678403 corr/f = -0.00176557449659
alpha =  2150
mse = 0.0213395900554 mse3 = 0.0193263463845 corr = 0.567508088252 corr/f = 0.000849154455796
alpha =  4630
mse = 0.0213448523614 mse3 = 0.0193154688661 corr = 0.567379234325 corr/f = -0.013370490629
alpha =  10000
mse = 0.0213334153005 mse3 = 0.0193146361223 corr = 0.567659437295 corr/f = 0.00047718043892
alpha =  21500
mse = 0.0213347973804 mse3 = 0.0193127918618 corr = 0.567627563092 corr/f = -0.00176512128907

# Plotting results
from mpl_toolkits.mplot3d import Axes3D

mse = np.array([[0.02578, 0.02422, 0.02309, 0.02186, 0.02128, 0.02144, 0.02134, 0.02134, 0.02134, 0.02134, 0.02134], [0.02586, 0.02527, 0.02314, 0.02165, 0.02119, 0.02143, 0.02135, 0.02134, 0.02134, 0.02134, 0.02134], [0.02607, 0.02511, 0.02320, 0.02194, 0.02120, 0.02137, 0.02134, 0.02133, 0.02134, 0.02134, 0.02134], [0.02608, 0.02471, 0.02326, 0.02194, 0.02123, 0.02138, 0.02134, 0.02135, 0.02134, 0.02134, 0.02134], [0.02656, 0.02499, 0.02351, 0.02208, 0.02119, 0.02138, 0.02134, 0.02134, 0.02133, 0.02133, 0.02134], [0.02617, 0.02536, 0.02377, 0.02178, 0.02120, 0.02134, 0.02138, 0.02134, 0.02133, 0.02133, 0.02134], [0.02643, 0.02522, 0.02396, 0.02193, 0.02124, 0.02134, 0.02133, 0.02134, 0.02134, 0.02133, 0.02133]])

xs, ys = np.meshgrid(regularization_params, hidden_layer_size)
fig = plt.figure()
ax = fig.gca(projection='3d')
surf = ax.plot_wireframe(np.log10(xs), ys, mse)
ax.set_xlabel('Log10(alpha)'); ax.set_ylabel('Hidden units'); ax.set_zlabel('MSE')

# Hidden layer size doesn't seem to matter so much as long as it is between 100-1000. Low layers seem more stable (close to ptimal result even with diff alphas)
# Better regularization term was always 215 (10^2.33)

# Searhcing whether 400 is better or worse than 200
regularization_params = 10 ** np.array([2, 2.2, 2.4, 2.6, 2.8, 3])
hidden_layer_size = [200, 400]

Layer size: 200
alpha =  100.0
mse = 0.0220333253456 mse3 = 0.0193833749654 corr = 0.563835795194 corr/f = 0.0644525553303
alpha =  158.489319246
mse = 0.0215248838887 mse3 = 0.0193002644536 corr = 0.571153584581 corr/f = 0.0743276674374
alpha =  251.188643151
mse = 0.0213196110593 mse3 = 0.0194337238678 corr = 0.569886747168 corr/f = 0.0665708024669
alpha =  398.107170553
mse = 0.0213319477386 mse3 = 0.0193475704975 corr = 0.56779248167 corr/f = 0.0194849958439
alpha =  630.95734448
mse = 0.0213425302574 mse3 = 0.0193304276071 corr = 0.567392294752 corr/f = 0.0204292299157
alpha =  1000.0
mse = 0.021345495831 mse3 = 0.019327212813 corr = 0.567336004014 corr/f = 0.0142517196875
Layer size: 400
alpha =  100.0
mse = 0.0217214514423 mse3 = 0.0191332419605 corr = 0.568800462709 corr/f = 0.0799652759934
alpha =  158.489319246
mse = 0.0211364783201 mse3 = 0.0191427142156 corr = 0.573893190122 corr/f = 0.0838578245505
alpha =  251.188643151
mse = 0.0213269499534 mse3 = 0.0194241674757 corr = 0.570079171374 corr/f = 0.0650127450523
alpha =  398.107170553
mse = 0.0213297570452 mse3 = 0.0193501747419 corr = 0.567800089072 corr/f = 0.0209545928471
alpha =  630.95734448
mse = 0.0213422368131 mse3 = 0.019327084102 corr = 0.567389070617 corr/f = 0.0220152728808
alpha =  1000.0
mse = 0.0213419011323 mse3 = 0.0193269836055 corr = 0.567411180712 corr/f = 0.0145263851509

# Strick with 400

# Test one network with two hidden layers (300->300)
regularization_params = [21.5, 46.3, 100, 215, 463, 1000, 2150, 4630, 10000]

alpha =  21.5
mse = 0.0228966996663 mse3 = 0.0196892463847 corr = 0.538560540501 corr/f = 0.0676796587479
alpha =  46.3
mse = 0.0220260386894 mse3 = 0.0195098401806 corr = 0.55774486202 corr/f = 0.0532677539696
alpha =  100
mse = 0.0214234003779 mse3 = 0.019263581127 corr = 0.567487576571 corr/f = 0.0280454641948
alpha =  215
mse = 0.0214523526927 mse3 = 0.0193270153001 corr = 0.564240993667 corr/f = 0.00159946791642
alpha =  463
mse = 0.0213819339502 mse3 = 0.0193399706604 corr = 0.566257509163 corr/f = -0.00117184619429
alpha =  1000
mse = 0.021352342929 mse3 = 0.0193126689912 corr = 0.567168860543 corr/f = -0.00958043061637
alpha =  2150
mse = 0.021339080185 mse3 = 0.019339352144 corr = 0.567480838063 corr/f = 0.00190309643806
alpha =  4630
mse = 0.0213398165077 mse3 = 0.0193378131581 corr = 0.567455277239 corr/f = -8.20879558356e-05
alpha =  10000
mse = 0.0213396112238 mse3 = 0.0193311283297 corr = 0.567462985749 corr/f = -0.000678624780432
# Worse results. Higher risk of overfitting.

# Test early stopping off (results may be better just because it has more data,
# anyways those are good news)
regularization_params = 10 ** np.array([2, 2.2, 2.4, 2.6, 2.8, 3])
layer_size = 400

alpha =  100.0
mse = 0.021822115954 mse3 = 0.0190615147663 corr = 0.555998107224 corr/f = 0.0744424501327
alpha =  158.489319246
mse = 0.0209844592553 mse3 = 0.0191216088448 corr = 0.577364254321 corr/f = 0.09561386117
alpha =  251.188643151
mse = 0.0209760471482 mse3 = 0.0191741523787 corr = 0.577398076758 corr/f = 0.0977662880596
alpha =  398.107170553
se = 0.0211942698959 mse3 = 0.0193383342083 corr = 0.571679075825 corr/f = 0.061776641471
alpha =  630.95734448
mse = 0.0213163003053 mse3 = 0.0193133423227 corr = 0.568139150887 corr/f = 0.0250667488862
alpha =  1000.0
mse = 0.0213322072951 mse3 = 0.0193074390209 corr = 0.567667220087 corr/f = 0.0180124172072


# Test SGD+ NAG + adaptive larning rate (early stoping off). This is pretty much the
# best I coudl do.
regularization_params = 10 ** np.array([2, 2.2, 2.4, 2.6, 2.8, 3])
layer_size = 400

alpha =  100.0
mse = 0.0215476880499 mse3 = 0.0190913976281 corr = 0.565911366868 corr/f = 0.0834153861356
alpha =  158.489319246
mse = 0.0210374974137 mse3 = 0.0189381169213 corr = 0.575219219726 corr/f = 0.0959284577956
alpha =  251.188643151
mse = 0.0209549012738 mse3 = 0.0191269740624 corr = 0.577713754425 corr/f = 0.102252712003
alpha =  398.107170553
mse = 0.0211683240322 mse3 = 0.0193243680884 corr = 0.572235791085 corr/f = 0.0783581690361
alpha =  630.95734448
mse = 0.0213151360533 mse3 = 0.0193325706545 corr = 0.568144921976 corr/f = 0.0269850428148
alpha =  1000.0
mse = 0.0213349746994 mse3 = 0.0193254273956 corr = 0.567574260392 corr/f = 0.0134085680914
# Takes more time and results are slightly better than ADAM. Time is still waaaay less tha fitting a ridge inm a single feature. Whole model takes 10 min!!

# Feature selection and then neural network. Deleting the noisy features may
# improve the answer. I do feature selection based on asingle y_i (y_train[:,50]).
# If it seems to work I could average over all features.
num_features = [100, 500, 1000, 3000]
regularization_params = 10 ** np.array([0, 0.333, 0.666, 1, 1.333, 1.666, 2, 2.333, 2.6666, 3])
layer_size = 400

for k in num_features:
	print(k, 'feature(s)'); selector = SelectKBest(f_regression, k=k).fit(X_train, y_train[:,50]); X_new = selector.transform(X_train); X_test_new = selector.transform(X_test);
	
	for alpha in regularization_params:
		print('alpha = ', alpha); model = MLPRegressor(hidden_layer_sizes = (layer_size,), alpha=alpha, max_iter=1000, random_state=123, algorithm='sgd', learning_rate='adaptive', tol = 1e-8); model.fit(X_new, y_train); y_pred = model.predict(X_test_new); mse = ((y_pred-y_test)**2).mean(); mse3 = ((y_pred[:,3] - y_test[:,3])**2).mean(); corr = 0; corrf = 0;
		for i in range(718):
			corr +=  np.corrcoef(y_pred[i,:], y_test[i,:])[0,1]
		for i in range(768):
			corrf +=  np.corrcoef(y_pred[:,i], y_test[:,i])[0,1]
		corr =	corr/718; corrf =	corrf/768; print('mse =', mse, 'mse3 =',mse3, 'corr =', corr, 'corr/f =', corrf)


100 feature(s)
alpha =  1.0
mse = 0.0238635681155 mse3 = 0.0211029239276 corr = 0.515343390954 corr/f = 0.0302434466513
alpha =  2.15278173472
mse = 0.0229672500409 mse3 = 0.0204554942258 corr = 0.531425712043 corr/f = 0.0340229228823
alpha =  4.63446919736
mse = 0.02187657334 mse3 = 0.019915469168 corr = 0.554957399611 corr/f = 0.055659758654
alpha =  10.0
mse = 0.0212054076639 mse3 = 0.0196978017393 corr = 0.571242335417 corr/f = 0.0822580021609
alpha =  21.5278173472
mse = 0.020987382678 mse3 = 0.01939522832 corr = 0.577132167239 corr/f = 0.095425022481
alpha =  46.3446919736
mse = 0.0210061027883 mse3 = 0.0193982338385 corr = 0.57679432947 corr/f = 0.089404991498
alpha =  100.0
mse = 0.0211230946148 mse3 = 0.0193956489477 corr = 0.573653745809 corr/f = 0.0701366685823
alpha =  215.278173472
mse = 0.0212822414609 mse3 = 0.0193444724006 corr = 0.56911675109 corr/f = 0.0521875790608
alpha =  464.087637808
mse = 0.0213367466246 mse3 = 0.0193251327115 corr = 0.567528080307 corr/f = 0.00368565660554
alpha =  1000.0
mse = 0.0213368340155 mse3 = 0.0193248170323 corr = 0.567523988082 corr/f = -0.00739587040845
500 feature(s)
alpha =  1.0
mse = 0.0255866380636 mse3 = 0.0232182054739 corr = 0.494160305014 corr/f = 0.0412720263862
alpha =  2.15278173472
mse = 0.0248204354967 mse3 = 0.0225147085293 corr = 0.504585476056 corr/f = 0.0465341260556
alpha =  4.63446919736
mse = 0.0234967982724 mse3 = 0.0210033619466 corr = 0.527276776695 corr/f = 0.0568947583711
alpha =  10.0
mse = 0.0222265761063 mse3 = 0.0199361468809 corr = 0.552176410877 corr/f = 0.0719176881352
alpha =  21.5278173472
mse = 0.0212732100993 mse3 = 0.0193809868808 corr = 0.571396216777 corr/f = 0.0925552073082
alpha =  46.3446919736
mse = 0.0208711029825 mse3 = 0.019346212311 corr = 0.580398962613 corr/f = 0.110550291122
alpha =  100.0
mse = 0.0209390260442 mse3 = 0.019399128318 corr = 0.57859870544 corr/f = 0.101947609801
alpha =  215.278173472
mse = 0.0211798465998 mse3 = 0.019384673722 corr = 0.572021165101 corr/f = 0.0639714002599
alpha =  464.087637808
mse = 0.0213320455703 mse3 = 0.019322874426 corr = 0.567667305213 corr/f = 0.0420130047454
alpha =  1000.0
mse = 0.0213364524764 mse3 = 0.0193239627772 corr = 0.56753513126 corr/f = 0.0169784725185
1000 feature(s)
alpha =  1.0
mse = 0.0278664552344 mse3 = 0.0253004959506 corr = 0.464416605331 corr/f = 0.0402574463068
alpha =  2.15278173472
mse = 0.0269369661471 mse3 = 0.0240489245782 corr = 0.470538204037 corr/f = 0.0440719462651
alpha =  4.63446919736
mse = 0.0249743714064 mse3 = 0.0223306447997 corr = 0.496952485205 corr/f = 0.0478986531606
alpha =  10.0
mse = 0.0232412244016 mse3 = 0.0211291213147 corr = 0.530872281107 corr/f = 0.0587219456359
alpha =  21.5278173472
mse = 0.0220210505992 mse3 = 0.020012704385 corr = 0.55522391602 corr/f = 0.0719138262376
alpha =  46.3446919736
mse = 0.021133408026 mse3 = 0.0194762447793 corr = 0.573492413235 corr/f = 0.0946342305035
alpha =  100.0
mse = 0.0209017642219 mse3 = 0.0193440772411 corr = 0.57931479843 corr/f = 0.107159128498
alpha =  215.278173472
mse = 0.0211115856841 mse3 = 0.0193780576628 corr = 0.573832753837 corr/f = 0.0814455338272
alpha =  464.087637808
mse = 0.0213083242315 mse3 = 0.0193341253205 corr = 0.568349899141 corr/f = 0.0402951337189
alpha =  1000.0
mse = 0.0213364794915 mse3 = 0.0193235888316 corr = 0.567535050885 corr/f = 0.0213979766597
3000 feature(s)
alpha =  1.0
mse = 0.0309779230158 mse3 = 0.0286391546492 corr = 0.418335041438 corr/f = 0.0256535777843 # Did not converge
alpha =  2.15278173472
mse = 0.0287801127092 mse3 = 0.0263343890718 corr = 0.442268039188 corr/f = 0.0294566096004 # Did not converge
alpha =  4.63446919736
mse = 0.0270129854278 mse3 = 0.0249716202641 corr = 0.465324312904 corr/f = 0.0328469759155 # Did not converge
alpha =  10.0
mse = 0.025377710219 mse3 = 0.0227543517814 corr = 0.490022020416 corr/f = 0.0369579013578
alpha =  21.5278173472
mse = 0.0234733297132 mse3 = 0.02109854676 corr = 0.524038022014 corr/f = 0.0479643455767
alpha =  46.3446919736
mse = 0.0218200083817 mse3 = 0.0196982282472 corr = 0.559232370992 corr/f = 0.0763474131438
alpha =  100.0
mse = 0.0210077013632 mse3 = 0.0191492179781 corr = 0.576184552134 corr/f = 0.0993754802087
alpha =  215.278173472
mse = 0.0210021326236 mse3 = 0.0193448766799 corr = 0.576724927516 corr/f = 0.100737138746
alpha =  464.087637808
mse = 0.021288619783 mse3 = 0.0193372381131 corr = 0.568890367544 corr/f = 0.0475782270684
alpha =  1000.0
mse = 0.0213370311191 mse3 = 0.0193240176896 corr = 0.567520347669 corr/f = 0.0111564084382

# Slightly better for a 1000-500, seems hard to explain, though.

# Trains fast (less than an hour) and results are average, could have it 
# as a baseline




###############################################################################
# Test how to deconvolve the predicted features by the xx_conv models.
from scipy.stats import gamma
from numpy.fft import fft, ifft
from sklearn.metrics import r2_score

# Bold without delay
with h5py.File('train_bold.h5', 'r') as Xs2_file:
	Xs2 = np.array(Xs2_file['responses'])
Xs2 = Xs2[10 : -10, :]
X_conv_train = Xs2[:-718,:]
X_conv_test = Xs2[-718:,:]

# True convolved features
with h5py.File('train_conv_feats.h5', 'r') as y_conv_file:
	y_conv = np.array(y_conv_file['feats'])
y_conv = y_conv[10:-10] 
y_conv_train = y_conv[:-718, 3]
y_conv_test = y_conv[-718:, 3]

# See whether I can recover y_train (not convolved features) from y_conv_train.
# I should be able to do this almost perfectly-

# Option 1: just shifting the answer by 5 seconds back
y_shifted = y_conv_train[5:]
np.corrcoef(y_shifted, y_train[:-5]) = 0.858486
# That's quite alright and quite simple. plots look fine, too

# Option 2: Using wiener deconvolution
timepoints = np.linspace(0,32,33)
hrf = gamma.pdf(timepoints, 7, scale=0.9) - 0.35 * gamma.pdf(timepoints, 13, scale=0.9) # 32-second canonical hrf
hrf /= hrf.sum()
SNR = 30
signal = y_conv_train
H = fft(hrf, len(signal))
wiener_filter = np.conj(H) / (H*np.conj(H) + (1 / SNR)**2)
y_deconv = np.real(ifft(wiener_filter * fft(signal)))

np.corrcoef(y_deconv, y_train) = 0.857966 # SNR = 1
np.corrcoef(y_deconv, y_train) = 0.931714 # SNR = 10
np.corrcoef(y_deconv, y_train) = 0.954629 # SNR =30
# this makes sense as y_conv is exactly np.convolve(hrf, y_train)

# I want to test that with predictions though as there SNR is gonna become a 
# hyperparameter
regularization_params = {'alpha': np.logspace(3.5, 5.5, 20)}
cv = GridSearchCV(Ridge(), regularization_params, cv=5, n_jobs=-1)
cv.fit(X_conv_train, y_conv_train)
model = cv.best_estimator_
y8_pred = model.predict(X_conv_test)

# Shifting it 5 secs
y_shifted = y8_pred[5:]
np.corrcoef(y_shifted, y_test[:-5]) = 0.257404
((y_shifted - y_test[:-5])**2).mean() = 0.01833
r2_score(y_test[:-5], y_shifted) = 0.04805

# At different shifts
np.corrcoef(y8_pred[3:], y_test[:-3]) = 0.18144444
np.corrcoef(y8_pred[4:], y_test[:-4]) = 0.25195873
np.corrcoef(y8_pred[5:], y_test[:-5]) = 0.25740413
np.corrcoef(y8_pred[6:], y_test[:-6]) = 0.22466334
np.corrcoef(y8_pred[7:], y_test[:-7]) = 0.19036582

# Deconvolved
SNR = 1
signal = y8_pred
H = fft(hrf, len(signal))
weiner_filter = np.conj(H) / (H*np.conj(H) + (1 / SNR)**2)
y8_deconv = np.real(ifft(weiner_filter * fft(signal)))

np.corrcoef(y8_deconv, y_test) = 0.270516
((y8_deconv - y_test)**2).mean() = 0.0243292
r2_score(y_test, y8_deconv) = -0.263949868
# Correlation is better than just shifting the other two are awful but they depend
# on the spread of the y_deconv which is probablñy off but can be adjusted using
# the training set.

# Results after dropping the last 5 (which could not be deconvolved properly)
np.corrcoef(y8_deconv[:-5], y_test[:-5]) = 0.272342
((y8_deconv[:-5] - y_test[:-5])**2).mean() = 0.02431880
r2_score(y_test[:-5], y8_deconv[:-5]) = -0.2627090
# Same as above just slightly better

plt.plot(y_test)
plt.plot(y_shifted)
plt.plot(y8_deconv)
# Like it. Seems like it is learning something.

# Deconvolving is better. And I haven't even tested for better SNRs which could be fitted with the trainig
np.corrcoef(y8_deconv, y_test) = 0.2573 # SNR = 0.1 , too smooth
np.corrcoef(y8_deconv, y_test) = 0.2705 # SNR = 1
np.corrcoef(y8_deconv, y_test) = 0.2482 # SNR = 10


# Find the best SNR (this uses the correct test predictions for cross-validation.
# I just want to know what would be the gold standard
SNRs = np.logspace(-1, 1, 20) 
signal = y8_pred
H = fft(hrf, len(signal))
for SNR in SNRs:
	weiner_filter = np.conj(H) / (H*np.conj(H) + (1 / SNR)**2)
	y8_deconv = np.real(ifft(weiner_filter * fft(signal)))
	print('SNR:', SNR, 'corr =', np.corrcoef(y8_deconv, y_test)[0,1], 'mse=', ((y8_deconv - y_test)**2).mean(), 'r2=', r2_score(y_test, y8_deconv))
	
SNR: 0.1 corr = 0.257331029022 mse= 0.0418394685535 r2= -1.17363693341
SNR: 0.12742749857 corr = 0.257489583682 mse= 0.0415528073472 r2= -1.15874435932
SNR: 0.162377673919 corr = 0.257742418096 mse= 0.0410984879794 r2= -1.13514163702
SNR: 0.206913808111 corr = 0.258141311883 mse= 0.040388932825 r2= -1.09827894868
SNR: 0.263665089873 corr = 0.258760412844 mse= 0.0393060371083 r2= -1.04202053512
SNR: 0.335981828628 corr = 0.259698172694 mse= 0.0377113114429 r2= -0.959171619372
SNR: 0.428133239872 corr = 0.26107053624 mse= 0.0354856468183 r2= -0.843544270444
SNR: 0.545559478117 corr = 0.262989918083 mse= 0.0326114806523 r2= -0.694226080058
SNR: 0.695192796178 corr = 0.265532550049 mse= 0.0292734853381 r2= -0.520811116882
SNR: 0.88586679041 corr = 0.268709230971 mse= 0.0258845655781 r2= -0.344750535585
SNR: 1.12883789168 corr = 0.272448853292 mse= 0.0229380631212 r2= -0.191674342552
SNR: 1.43844988829 corr = 0.276573355593 mse= 0.0207546747558 r2= -0.0782433226301
SNR: 1.83298071083 corr = 0.280735545311 mse= 0.0193566651365 r2= -0.00561416535648
SNR: 2.33572146909 corr = 0.284336993965 mse= 0.0185651366365 r2= 0.0355071882557
SNR: 2.97635144163 corr = 0.286499094494 mse= 0.0181714042417 r2= 0.0559623064693
SNR: 3.79269019073 corr = 0.286177367018 mse= 0.0180340866096 r2= 0.0630962086718
SNR: 4.83293023857 corr = 0.282440458972 mse= 0.0180931447526 r2= 0.0600280300991
SNR: 6.15848211066 corr = 0.274791197323 mse= 0.0183525147511 r2= 0.0465532841809
SNR: 7.84759970351 corr = 0.263281685402 mse= 0.0188674681146 r2= 0.0198005148805
SNR: 10.0 corr = 0.248260957521 mse= 0.0197529845342 r2= -0.0262036831027
# Best is around 3. Results are fine. Weirdly best mse comes at a higher SNR ~3.8 (more noise).

# Now using the training set
SNRs = np.logspace(-1, 1, 20) 
signal = model.predict(X_conv_train)
H = fft(hrf, len(signal))
for SNR in SNRs:
	wiener_filter = np.conj(H) / (H*np.conj(H) + (1 / SNR)**2)
	y8_deconv = np.real(ifft(wiener_filter * fft(signal)))
	print('SNR:', SNR, 'corr =', np.corrcoef(y8_deconv, y_train)[0,1], 'mse=', ((y8_deconv - y_train)**2).mean(),  'r2=', r2_score(y_train, y8_deconv))
	
SNR: 0.1 corr = 0.688404059432 mse= 0.0393721295399 r2= -1.03230183295
SNR: 0.12742749857 corr = 0.688559046433 mse= 0.0390487762948 r2= -1.01561105701
SNR: 0.162377673919 corr = 0.688804381882 mse= 0.0385364597241 r2= -0.989166414108
SNR: 0.206913808111 corr = 0.689186866874 mse= 0.0377366855078 r2= -0.947883846346
SNR: 0.263665089873 corr = 0.68976919952 mse= 0.0365168780232 r2= -0.884920094683
SNR: 0.335981828628 corr = 0.690624377313 mse= 0.0347219858741 r2= -0.792271750611
SNR: 0.428133239872 corr = 0.691815282027 mse= 0.0322190406636 r2= -0.663075280959
SNR: 0.545559478117 corr = 0.693354190152 mse= 0.0289880376077 r2= -0.496298083243
SNR: 0.695192796178 corr = 0.695152441188 mse= 0.0252316052862 r2= -0.302399394461
SNR: 0.88586679041 corr = 0.696991063735 mse= 0.0214016375981 r2= -0.104704973471
SNR: 1.12883789168 corr = 0.69853249158 mse= 0.018038496465 r2= 0.0688928981488
SNR: 1.43844988829 corr = 0.69934510581 mse= 0.0154992248963 r2= 0.199964453683
SNR: 1.83298071083 corr = 0.6988989032 mse= 0.0138212060881 r2= 0.286580055619
SNR: 2.33572146909 corr = 0.696529382332 mse= 0.0128206769665 r2= 0.338225145474
SNR: 2.97635144163 corr = 0.691379329128 mse= 0.0122708330947 r2= 0.366606864254
SNR: 3.79269019073 corr = 0.68232691424 mse= 0.0120054768835 r2= 0.380303962196
SNR: 4.83293023857 corr = 0.667932299291 mse= 0.011937964078 r2= 0.383788823184
SNR: 6.15848211066 corr = 0.64645091159 mse= 0.0120478118849 r2= 0.3781187235
SNR: 7.84759970351 corr = 0.61602353503 mse= 0.0123712068335 r2= 0.361425794912
SNR: 10.0 corr = 0.575252359882 mse= 0.0130069463825 r2= 0.328610332155
# Best correlation at 1.4. Best mse at 4.8. ANyway, it's not a bad proxy to select
# SNR. I was expecting for the SNR to be bigger than when calculated on the tes set as traioning set predictions do have more signal in them as they are better than test set predictions. That is odd, also, what is with the best mse being a different sNR.
# Maybe correlation is better because, agian, it does not depend on ther magnitude of y8_deconv.	
		
# Test with y_5 to see whether the same SNR holds or what would be a good search range for SNRs.
y_conv_train = y_conv[:-718, 5]
y_conv_test = y_conv[-718:, 5]
y_train = y[:-718, 5]
y_test = y[-718:, 5]

regularization_params = {'alpha': np.logspace(3.5, 5.5, 20)}
cv = GridSearchCV(Ridge(), regularization_params, cv=5, n_jobs=-1)
cv.fit(X_conv_train, y_conv_train)
model = cv.best_estimator_
y8_pred = model.predict(X_conv_test)

# Shifting it 5 secs
y_shifted = y8_pred[5:]
np.corrcoef(y_shifted, y_test[:-5]) = 0.416856
((y_shifted - y_test[:-5])**2).mean() = 0.027964
r2_score(y_test[:-5], y_shifted) = 0.158943

# At different shifts
np.corrcoef(y8_pred[3:], y_test[:-3]) = 0.375331
np.corrcoef(y8_pred[4:], y_test[:-4]) = 0.41222
np.corrcoef(y8_pred[5:], y_test[:-5]) = 0.416856
np.corrcoef(y8_pred[6:], y_test[:-6]) = 0.40321
np.corrcoef(y8_pred[7:], y_test[:-7]) = 0.36231

# Deconvolved
SNR = 1
signal = y8_pred
H = fft(hrf, len(signal))
wiener_filter = np.conj(H) / (H*np.conj(H) + (1 / SNR)**2)
y8_deconv = np.real(ifft(wiener_filter * fft(signal)))

np.corrcoef(y8_deconv, y_test) = 0.449832
((y8_deconv - y_test)**2).mean() = 0.037125
r2_score(y_test, y8_deconv) = -0.115889
# Again, deconvolution is better than just shifting the data. And again, only for
# correlation, I guess the deconvolution messes up the scale

# Using the test data to get the best SNR
SNRs = np.logspace(-1, 1, 20) 
signal = y8_pred
H = fft(hrf, len(signal))
for SNR in SNRs:
		wiener_filter = np.conj(H) / (H*np.conj(H) + (1 / SNR)**2)
		y8_deconv = np.real(ifft(wiener_filter * fft(signal)))
		print('SNR:', SNR, 'corr =', np.corrcoef(y8_deconv, y_test)[0,1], 'mse=', ((y8_deconv - y_test)**2).mean(), 'r2=', r2_score(y_test, y8_deconv))
		
SNR: 0.1 corr = 0.457794104102 mse= 0.0724715881496 r2= -1.17828977166
SNR: 0.12742749857 corr = 0.457730135676 mse= 0.0718680395315 r2= -1.16014881718
SNR: 0.162377673919 corr = 0.457626737067 mse= 0.0709127367317 r2= -1.13143513268
SNR: 0.206913808111 corr = 0.457460102794 mse= 0.0694238315873 r2= -1.0866828797
SNR: 0.263665089873 corr = 0.457192903395 mse= 0.0671589413882 r2= -1.0186067235
SNR: 0.335981828628 corr = 0.456768004584 mse= 0.0638405188792 r2= -0.918864383172
SNR: 0.428133239872 corr = 0.456101327322 mse= 0.0592452811317 r2= -0.780744609074
SNR: 0.545559478117 corr = 0.455075955366 mse= 0.0533807410965 r2= -0.604473219136
SNR: 0.695192796178 corr = 0.453539098126 mse= 0.0466889424238 r2= -0.403336787952
SNR: 0.88586679041 corr = 0.451296212659 mse= 0.0400737884779 r2= -0.204504079213
SNR: 1.12883789168 corr = 0.448086946015 mse= 0.0345585037227 r2= -0.0387303094233
SNR: 1.43844988829 corr = 0.443541127739 mse= 0.0307526704493 r2= 0.0756622118908
SNR: 1.83298071083 corr = 0.437147473607 mse= 0.0286261724484 r2= 0.139578692307
SNR: 2.33572146909 corr = 0.428254914041 mse= 0.0277542357069 r2= 0.165786630261
SNR: 2.97635144163 corr = 0.416083291905 mse= 0.0276905091771 r2= 0.167702068455
SNR: 3.79269019073 corr = 0.399778467295 mse= 0.0281637159108 r2= 0.153478820225
SNR: 4.83293023857 corr = 0.378627622559 mse= 0.0290963727632 r2= 0.125445808476
SNR: 6.15848211066 corr = 0.352408903525 mse= 0.030560560506 r2= 0.0814364902677
SNR: 7.84759970351 corr = 0.321578753796 mse= 0.0327508856907 r2= 0.015601546283
SNR: 10.0 corr = 0.287030513527 mse= 0.0360211325275 r2= -0.0826927703918
# Best correlation is less than 0.1 (it plateauas at 0.45789 at around 0.001), best r2 at around 3.

	
# Now using the training set
SNRs = np.logspace(-1, 1, 20) 
signal = model.predict(X_conv_train)
H = fft(hrf, len(signal))
for SNR in SNRs:
	wiener_filter = np.conj(H) / (H*np.conj(H) + (1 / SNR)**2)
	y8_deconv = np.real(ifft(wiener_filter * fft(signal)))
	print('SNR:', SNR, 'corr =', np.corrcoef(y8_deconv, y_train)[0,1], 'mse=', ((y8_deconv - y_train)**2).mean(),  'r2=', r2_score(y_train, y8_deconv))
	
SNR: 0.1 corr = 0.746051353813 mse= 0.0816292328095 r2= -1.12453601711
SNR: 0.12742749857 corr = 0.746201447019 mse= 0.0808784391688 r2= -1.10499536879
SNR: 0.162377673919 corr = 0.74643900549 mse= 0.0796893819418 r2= -1.07404818458
SNR: 0.206913808111 corr = 0.746809312482 mse= 0.0778343576579 r2= -1.02576810441
SNR: 0.263665089873 corr = 0.747373062891 mse= 0.0750079401178 r2= -0.952205905472
SNR: 0.335981828628 corr = 0.748201187208 mse= 0.0708553101321 r2= -0.844126830529
SNR: 0.428133239872 corr = 0.749356078264 mse= 0.0650773364262 r2= -0.693745492599
SNR: 0.545559478117 corr = 0.750855344095 mse= 0.0576414785418 r2= -0.500214972345
SNR: 0.695192796178 corr = 0.752629311345 mse= 0.0490309007068 r2= -0.276110419245
SNR: 0.88586679041 corr = 0.754500275669 mse= 0.0402949181922 r2= -0.0487420016046
SNR: 1.12883789168 corr = 0.756194058825 mse= 0.0326686233186 r2= 0.149744956786
SNR: 1.43844988829 corr = 0.757346669876 mse= 0.0269516043324 r2= 0.298539847156
SNR: 1.83298071083 corr = 0.757473046203 mse= 0.0232105473081 r2= 0.395907053935
SNR: 2.33572146909 corr = 0.755920001948 mse= 0.0210166915236 r2= 0.453005785236
SNR: 2.97635144163 corr = 0.75182540212 mse= 0.0198541777016 r2= 0.483262133364
SNR: 3.79269019073 corr = 0.744081134131 mse= 0.0193526068306 r2= 0.49631634622
SNR: 4.83293023857 corr = 0.7313208427 mse= 0.0193261107892 r2= 0.497005949593
SNR: 6.15848211066 corr = 0.711939456507 mse= 0.0197391737242 r2= 0.486255302398
SNR: 7.84759970351 corr = 0.684113646115 mse= 0.020683386922 r2= 0.46168058967
SNR: 10.0 corr = 0.64595121153 mse= 0.0223966992898 r2= 0.417088796893
# best at around 2, so training SNr is higher than the best

# SNR seems like quite an important hyperparameter, selecting the best with the training set makes me lose a couple percent in correlation. For y_3, the best selected with training will produce corr = 0.27657 (compared to the very best 0.286) and for y_5 it will produce 0.4371 compared to 0.4578. Maybe I can just live with it, but I wish I hadn't.
# Yep, SNR mostly controls the smoothness. Results are not that bad even if SNr is slightly off.

# i like logspace(-2, 1.5, 50)

# try another one y_i=100
y_conv_train = y_conv[:-718, 100]
y_conv_test = y_conv[-718:, 100]
y_train = y[:-718, 100]
y_test = y[-718:, 100]

regularization_params = {'alpha': np.logspace(3.5, 5.5, 20)}
cv = GridSearchCV(Ridge(), regularization_params, cv=5, n_jobs=-1)
cv.fit(X_conv_train, y_conv_train)
model = cv.best_estimator_
y8_pred = model.predict(X_conv_test)

# Shifting it 5 secs
y_shifted = y8_pred[5:]
np.corrcoef(y_shifted, y_test[:-5]) = 0.341707
((y_shifted - y_test[:-5])**2).mean() = 0.0390328
r2_score(y_test[:-5], y_shifted) = 0.1134189

# Using the test data to get the best SNR
SNRs = np.logspace(-1, 1, 20) 
signal = y8_pred
H = fft(hrf, len(signal))
for SNR in SNRs:
		wiener_filter = np.conj(H) / (H*np.conj(H) + (1 / SNR)**2)
		y8_deconv = np.real(ifft(wiener_filter * fft(signal)))
		print('SNR:', SNR, 'corr =', np.corrcoef(y8_deconv, y_test)[0,1], 'mse=', ((y8_deconv - y_test)**2).mean(), 'r2=', r2_score(y_test, y8_deconv))
		
SNR: 0.1 corr = 0.35271777056 mse= 0.101445990166 r2= -1.31750690073
SNR: 0.12742749857 corr = 0.352692736868 mse= 0.100637020984 r2= -1.29902621305
SNR: 0.162377673919 corr = 0.352651482874 mse= 0.0993555811331 r2= -1.26975205748
SNR: 0.206913808111 corr = 0.352583138373 mse= 0.0973559424887 r2= -1.22407083983
SNR: 0.263665089873 corr = 0.352469473046 mse= 0.0943084852411 r2= -1.15445248242
SNR: 0.335981828628 corr = 0.352280884178 mse= 0.0898312086752 r2= -1.05217027963
SNR: 0.428133239872 corr = 0.351973337327 mse= 0.0836071850143 r2= -0.909984099963
SNR: 0.545559478117 corr = 0.351493033199 mse= 0.0756230674575 r2= -0.727589039262
SNR: 0.695192796178 corr = 0.35079931865 mse= 0.0664544338755 r2= -0.518134022243
SNR: 0.88586679041 corr = 0.349902968391 mse= 0.0573210939116 r2= -0.309485278625
SNR: 1.12883789168 corr = 0.348876603729 mse= 0.0496287961607 r2= -0.133756764457
SNR: 1.43844988829 corr = 0.347776125609 mse= 0.0442229005399 r2= -0.0102605041765
SNR: 1.83298071083 corr = 0.346482507274 mse= 0.0410531253431 r2= 0.0621521745329
SNR: 2.33572146909 corr = 0.344568793858 mse= 0.0395047990164 r2= 0.0975232812765
SNR: 2.97635144163 corr = 0.341303858684 mse= 0.0389187550016 r2= 0.110911302293
SNR: 3.79269019073 corr = 0.335821622157 mse= 0.0388594739547 r2= 0.112265562182
SNR: 4.83293023857 corr = 0.327354497133 mse= 0.0391298638123 r2= 0.106088577169
SNR: 6.15848211066 corr = 0.315359077424 mse= 0.0397029379441 r2= 0.0929968497086
SNR: 7.84759970351 corr = 0.29946403312 mse= 0.0406760710463 r2= 0.0707658805401
SNR: 10.0 corr = 0.2793579846 mse= 0.0422778080475 r2= 0.0341746210202
#plateasu at 0.035275 at SNr 0.018, r2 at around 4. Yep, go with corr

# Now using the training set
SNRs = np.logspace(-1, 1, 20) 
signal = model.predict(X_conv_train)
H = fft(hrf, len(signal))
for SNR in SNRs:
	wiener_filter = np.conj(H) / (H*np.conj(H) + (1 / SNR)**2)
	y8_deconv = np.real(ifft(wiener_filter * fft(signal)))
	print('SNR:', SNR, 'corr =', np.corrcoef(y8_deconv, y_train)[0,1], 'mse=', ((y8_deconv - y_train)**2).mean(),  'r2=', r2_score(y_train, y8_deconv))
	
	SNR: 0.1 corr = 0.64909294452 mse= 0.107144664879 r2= -1.38939481329
SNR: 0.12742749857 corr = 0.649254356528 mse= 0.106240685358 r2= -1.36923548961
SNR: 0.162377673919 corr = 0.649510011433 mse= 0.104807894314 r2= -1.33728332949
SNR: 0.206913808111 corr = 0.649908983997 mse= 0.102569885689 r2= -1.28737430035
SNR: 0.263665089873 corr = 0.650517489663 mse= 0.0991535929327 r2= -1.21118877864
SNR: 0.335981828628 corr = 0.651413955882 mse= 0.0941207052748 r2= -1.09895215277
SNR: 0.428133239872 corr = 0.652669776336 mse= 0.0870918995696 r2= -0.942205273082
SNR: 0.545559478117 corr = 0.654310862262 mse= 0.078004129526 r2= -0.739542166796
SNR: 0.695192796178 corr = 0.656269657488 mse= 0.0674269043615 r2= -0.503663255086
SNR: 0.88586679041 corr = 0.658353838965 mse= 0.0566471634123 r2= -0.263268111367
SNR: 1.12883789168 corr = 0.660241732024 mse= 0.0472127773725 r2= -0.0528752458361
SNR: 1.43844988829 corr = 0.661469307123 mse= 0.0401438956957 r2= 0.104765353752
SNR: 1.83298071083 corr = 0.661377168422 mse= 0.0355322369822 r2= 0.20760830373
SNR: 2.33572146909 corr = 0.659043202791 mse= 0.0328296186408 r2= 0.267878427816
SNR: 2.97635144163 corr = 0.653252521438 mse= 0.0313707006835 r2= 0.300413234884
SNR: 3.79269019073 corr = 0.642551802968 mse= 0.0306720818906 r2= 0.315992882474
SNR: 4.83293023857 corr = 0.62541335055 mse= 0.0304770299351 r2= 0.320342666306
SNR: 6.15848211066 corr = 0.600477154388 mse= 0.0307010398559 r2= 0.315347101257
SNR: 7.84759970351 corr = 0.566827496688 mse= 0.0313834514478 r2= 0.300128884653
SNR: 10.0 corr = 0.524321726569 mse= 0.0326767401776 r2= 0.271287715692
# best at 1.43, best r2 at 4.85

# also, in the three examples the best SNR with the trainng set is around 1.5
# maybe is just a coincidence.
# The SNr selected with the traing set is slightly more noisier, but not for much.
# That is the other way around for y_3, not sure why.

# Conclusion: Do deconvolve rater than just shift, use the training set, use corr rather than mse, use a logscale -2, 1.5, 50.


